<!DOCTYPE html>

<html data-content_root="../" lang="en" x-data="{activeSection: ''}">
<head>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<meta charset="utf-8"/>
<meta content="#ffffff" media="(prefers-color-scheme: light)" name="theme-color"/>
<meta content="#030711" media="(prefers-color-scheme: dark)" name="theme-color"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>

<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-NRNXK42JKJ"></script>
<script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-NRNXK42JKJ');
    </script>
<title>ImageNet Robustness with TENT | torch&lt;span style='border-radius: 4px; color: white; text-justify: none; padding: 0px 2px 0px 2px; background: linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3)); -moz-linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3)); -webkit-linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3));'&gt;-ttt&lt;/span&gt;</title>
<meta content="ImageNet Robustness with TENT | torch&lt;span style='border-radius: 4px; color: white; text-justify: none; padding: 0px 2px 0px 2px; background: linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3)); -moz-linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3)); -webkit-linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3));'&gt;-ttt&lt;/span&gt;" property="og:title"/>
<meta content="ImageNet Robustness with TENT | torch&lt;span style='border-radius: 4px; color: white; text-justify: none; padding: 0px 2px 0px 2px; background: linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3)); -moz-linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3)); -webkit-linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3));'&gt;-ttt&lt;/span&gt;" name="twitter:title"/>
<link href="../_static/pygments.css?v=82fa1eaf" rel="stylesheet" type="text/css"/>
<link href="../_static/theme.css?v=c0d22bf5" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery.css?v=d2d258e8" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-binder.css?v=f4aeca0c" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-dataframe.css?v=2082cf3c" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" rel="stylesheet" type="text/css"/>
<link href="../_static/css/custom.css?v=5be90d75" rel="stylesheet" type="text/css"/>
<link href="../_static/css/docstring_custom.css?v=c7bea3a5" rel="stylesheet" type="text/css"/>
<link href="../_static/torch-ttt.svg" rel="icon"/>
<link href="../search.html" rel="search" title="Search"/>
<link href="../genindex.html" rel="index" title="Index"/>
<link href="../api.html" rel="next" title="API Reference"/>
<link href="01_mnist_TTT.html" rel="prev" title="TTT for Corrupted MNIST"/>
</head>
<body :class="{ 'overflow-hidden': showSidebar }" class="min-h-screen font-sans antialiased bg-background text-foreground" x-data="{ showSidebar: false, showScrollTop: false }">
<div @click.self="showSidebar = false" class="fixed inset-0 z-50 overflow-hidden bg-background/80 backdrop-blur-sm md:hidden" x-cloak="" x-show="showSidebar"></div><div class="relative flex flex-col min-h-screen" id="page"><a class="absolute top-0 left-0 z-[100] block bg-background p-4 text-xl transition -translate-x-full opacity-0 focus:translate-x-0 focus:opacity-100" href="#content">
      Skip to content
    </a><header class="sticky top-0 z-40 w-full border-b shadow-sm border-border bg-background/90 backdrop-blur"><div class="container flex items-center h-14">
<div class="hidden mr-4 md:flex">
<a class="flex items-center mr-6" href="../index.html">
<img alt="Logo" class="mr-2 dark:invert" height="24" src="../_static/torch-ttt.svg" width="24"/><span class="hidden font-bold sm:inline-block text-clip whitespace-nowrap">torch<span style="border-radius: 4px; color: white; text-justify: none; padding: 0px 2px 0px 2px; background: linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3)); -moz-linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3)); -webkit-linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3));">-ttt</span></span>
</a></div><button @click="showSidebar = true" class="inline-flex items-center justify-center h-10 px-0 py-2 mr-2 text-base font-medium transition-colors rounded-md hover:text-accent-foreground hover:bg-transparent md:hidden" type="button">
<svg aria-hidden="true" fill="currentColor" height="24" viewbox="0 96 960 960" width="24" xmlns="http://www.w3.org/2000/svg">
<path d="M152.587 825.087q-19.152 0-32.326-13.174t-13.174-32.326q0-19.152 13.174-32.326t32.326-13.174h440q19.152 0 32.326 13.174t13.174 32.326q0 19.152-13.174 32.326t-32.326 13.174h-440Zm0-203.587q-19.152 0-32.326-13.174T107.087 576q0-19.152 13.174-32.326t32.326-13.174h320q19.152 0 32.326 13.174T518.087 576q0 19.152-13.174 32.326T472.587 621.5h-320Zm0-203.587q-19.152 0-32.326-13.174t-13.174-32.326q0-19.152 13.174-32.326t32.326-13.174h440q19.152 0 32.326 13.174t13.174 32.326q0 19.152-13.174 32.326t-32.326 13.174h-440ZM708.913 576l112.174 112.174q12.674 12.674 12.674 31.826t-12.674 31.826Q808.413 764.5 789.261 764.5t-31.826-12.674l-144-144Q600 594.391 600 576t13.435-31.826l144-144q12.674-12.674 31.826-12.674t31.826 12.674q12.674 12.674 12.674 31.826t-12.674 31.826L708.913 576Z"></path>
</svg>
<span class="sr-only">Toggle navigation menu</span>
</button>
<div class="flex items-center justify-between flex-1 gap-2 sm:gap-4 md:justify-end">
<div class="flex-1 w-full md:w-auto md:flex-none"><form @keydown.k.window.meta="$refs.search.focus()" action="../search.html" class="relative flex items-center group" id="searchbox" method="get">
<input aria-label="Search the docs" class="inline-flex items-center font-medium transition-colors bg-transparent focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 ring-offset-background border border-input hover:bg-accent focus:bg-accent hover:text-accent-foreground focus:text-accent-foreground hover:placeholder-accent-foreground py-2 px-4 relative h-9 w-full justify-start rounded-[0.5rem] text-sm text-muted-foreground sm:pr-12 md:w-40 lg:w-64" id="search-input" name="q" placeholder="Search ..." type="search" x-ref="search"/>
<kbd class="pointer-events-none absolute right-1.5 top-2 hidden h-5 select-none text-muted-foreground items-center gap-1 rounded border border-border bg-muted px-1.5 font-mono text-[10px] font-medium opacity-100 sm:flex group-hover:bg-accent group-hover:text-accent-foreground">
<span class="text-xs">âŒ˜</span>
    K
  </kbd>
</form>
</div>
<nav class="flex items-center gap-1">
<a href="https://github.com/nikitadurasov/torch-ttt" rel="noopener nofollow" title="Visit repository on GitHub">
<div class="inline-flex items-center justify-center px-0 text-sm font-medium transition-colors rounded-md hover:bg-accent hover:text-accent-foreground h-9 w-9">
<svg fill="currentColor" height="26px" style="margin-top:-2px;display:inline" viewbox="0 0 45 44" xmlns="http://www.w3.org/2000/svg"><path clip-rule="evenodd" d="M22.477.927C10.485.927.76 10.65.76 22.647c0 9.596 6.223 17.736 14.853 20.608 1.087.2 1.483-.47 1.483-1.047 0-.516-.019-1.881-.03-3.693-6.04 1.312-7.315-2.912-7.315-2.912-.988-2.51-2.412-3.178-2.412-3.178-1.972-1.346.149-1.32.149-1.32 2.18.154 3.327 2.24 3.327 2.24 1.937 3.318 5.084 2.36 6.321 1.803.197-1.403.759-2.36 1.379-2.903-4.823-.548-9.894-2.412-9.894-10.734 0-2.37.847-4.31 2.236-5.828-.224-.55-.969-2.759.214-5.748 0 0 1.822-.584 5.972 2.226 1.732-.482 3.59-.722 5.437-.732 1.845.01 3.703.25 5.437.732 4.147-2.81 5.967-2.226 5.967-2.226 1.185 2.99.44 5.198.217 5.748 1.392 1.517 2.232 3.457 2.232 5.828 0 8.344-5.078 10.18-9.916 10.717.779.67 1.474 1.996 1.474 4.021 0 2.904-.027 5.247-.027 5.96 0 .58.392 1.256 1.493 1.044C37.981 40.375 44.2 32.24 44.2 22.647c0-11.996-9.726-21.72-21.722-21.72" fill="currentColor" fill-rule="evenodd"></path></svg>
</div>
</a>
</nav>
</div>
</div>
</header>
<div class="flex-1"><div class="container md:grid md:grid-cols-[220px_minmax(0,1fr)] md:gap-6 lg:grid-cols-[240px_minmax(0,1fr)] lg:gap-10"><aside :aria-hidden="!showSidebar" :class="{ 'translate-x-0': showSidebar }" class="fixed inset-y-0 left-0 md:top-14 z-50 md:z-30 bg-background md:bg-transparent transition-all duration-100 -translate-x-full md:translate-x-0 ml-0 p-6 md:p-0 md:-ml-2 md:h-[calc(100vh-3.5rem)] w-5/6 md:w-full overflow-y-auto border-r border-border md:sticky" id="left-sidebar">
<a class="justify-start text-sm md:!hidden bg-background" href="../index.html">
<img alt="Logo" class="mr-2 dark:invert" height="16" src="../_static/torch-ttt.svg" width="16"/><span class="font-bold text-clip whitespace-nowrap">torch<span style="border-radius: 4px; color: white; text-justify: none; padding: 0px 2px 0px 2px; background: linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3)); -moz-linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3)); -webkit-linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3));">-ttt</span></span>
</a>
<div class="relative overflow-hidden md:overflow-auto my-4 md:my-0">
<div class="overflow-y-auto h-full w-full relative pr-6"><nav class="table w-full min-w-full my-6 lg:my-8">
<p class="caption" role="heading"><span class="caption-text">Getting Started:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quickstart.html">Quick Start</a></li>
<li class="toctree-l1 current" x-data="{ expanded: $el.classList.contains('current') ? true : false }"><a :class="{ 'expanded' : expanded }" @click="expanded = !expanded" class="reference internal expandable" href="index.html">Tutorials<button @click.prevent.stop="expanded = !expanded" type="button"><span class="sr-only"></span><svg fill="currentColor" height="18px" stroke="none" viewbox="0 0 24 24" width="18px" xmlns="http://www.w3.org/2000/svg"><path d="M10 6L8.59 7.41 13.17 12l-4.58 4.59L10 18l6-6z"></path></svg></button></a><ul class="current" x-show="expanded">
<li class="toctree-l2"><a class="reference internal" href="01_mnist_TTT.html">TTT for Corrupted MNIST</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">ImageNet Robustness with TENT</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Documentation:</span></p>
<ul>
<li class="toctree-l1" x-data="{ expanded: $el.classList.contains('current') ? true : false }"><a :class="{ 'expanded' : expanded }" @click="expanded = !expanded" class="reference internal expandable" href="../api.html">API Reference<button @click.prevent.stop="expanded = !expanded" type="button"><span class="sr-only"></span><svg fill="currentColor" height="18px" stroke="none" viewbox="0 0 24 24" width="18px" xmlns="http://www.w3.org/2000/svg"><path d="M10 6L8.59 7.41 13.17 12l-4.58 4.59L10 18l6-6z"></path></svg></button></a><ul x-show="expanded">
<li class="toctree-l2"><a class="reference internal" href="../_autosummary/torch_ttt.engine.ttt_engine.TTTEngine.html">torch_ttt.engine.ttt_engine.TTTEngine</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_autosummary/torch_ttt.engine.ttt_pp_engine.TTTPPEngine.html">torch_ttt.engine.ttt_pp_engine.TTTPPEngine</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_autosummary/torch_ttt.engine.masked_ttt_engine.MaskedTTTEngine.html">torch_ttt.engine.masked_ttt_engine.MaskedTTTEngine</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_autosummary/torch_ttt.engine.actmad_engine.ActMADEngine.html">torch_ttt.engine.actmad_engine.ActMADEngine</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_autosummary/torch_ttt.engine.tent_engine.TentEngine.html">torch_ttt.engine.tent_engine.TentEngine</a></li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
<button @click="showSidebar = false" class="absolute md:hidden right-4 top-4 rounded-sm opacity-70 transition-opacity hover:opacity-100" type="button">
<svg class="h-4 w-4" fill="currentColor" height="24" stroke="none" viewbox="0 96 960 960" width="24" xmlns="http://www.w3.org/2000/svg">
<path d="M480 632 284 828q-11 11-28 11t-28-11q-11-11-11-28t11-28l196-196-196-196q-11-11-11-28t11-28q11-11 28-11t28 11l196 196 196-196q11-11 28-11t28 11q11 11 11 28t-11 28L536 576l196 196q11 11 11 28t-11 28q-11 11-28 11t-28-11L480 632Z"></path>
</svg>
</button>
</aside>
<main class="relative py-6 lg:gap-10 lg:py-8 xl:grid xl:grid-cols-[1fr_300px]">
<div class="w-full min-w-0 mx-auto">
<nav aria-label="breadcrumbs" class="flex items-center mb-4 space-x-1 text-sm text-muted-foreground">
<a class="overflow-hidden text-ellipsis whitespace-nowrap hover:text-foreground" href="../index.html">
<span class="hidden md:inline">torch<span style="border-radius: 4px; color: white; text-justify: none; padding: 0px 2px 0px 2px; background: linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3)); -moz-linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3)); -webkit-linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3));">-ttt</span></span>
<svg aria-label="Home" class="md:hidden" fill="currentColor" height="18" stroke="none" viewbox="0 96 960 960" width="18" xmlns="http://www.w3.org/2000/svg">
<path d="M240 856h120V616h240v240h120V496L480 316 240 496v360Zm-80 80V456l320-240 320 240v480H520V696h-80v240H160Zm320-350Z"></path>
</svg>
</a>
<div class="mr-1">/</div><a class="hover:text-foreground overflow-hidden text-ellipsis whitespace-nowrap" href="index.html">Tutorials</a>
<div class="mr-1">/</div><span aria-current="page" class="font-medium text-foreground overflow-hidden text-ellipsis whitespace-nowrap">ImageNet Robustness with TENT</span>
</nav>
<div id="content" role="main">
<div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-auto-examples-02-imagenet-tent-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="imagenet-robustness-with-tent">
<span id="sphx-glr-auto-examples-02-imagenet-tent-py"></span><h1>ImageNet Robustness with TENT<a @click.prevent="window.navigator.clipboard.writeText($el.href); $el.setAttribute('data-tooltip', 'Copied!'); setTimeout(() =&gt; $el.setAttribute('data-tooltip', 'Copy link to this element'), 2000)" aria-label="Copy link to this element" class="headerlink" data-tooltip="Copy link to this element" href="#imagenet-robustness-with-tent"><span>#</span></a></h1>
<p>Discover how test-time training can improve model performance on corrupted versions of ImageNet using <cite>torch-ttt</cite>.</p>
<p>In this tutorial, we demonstrate how test-time adaptation methods such as <a class="reference external" href="https://arxiv.org/abs/2002.04765">Tent</a> can help restore accuracy when evaluating models on <a class="reference external" href="https://github.com/hendrycks/robustness">ImageNet-C</a>, a corrupted variant of the ImageNet dataset. We leverage the <a class="reference external" href="https://github.com/nikitadurasov/torch-ttt">torch-ttt</a> library for easy and flexible integration.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="nb">print</span><span class="p">(</span><span class="s2">"Uncomment the line below to install torch-ttt if you're running this in Colab"</span><span class="p">)</span>
</span><span id="line-2"><span class="c1"># !pip install git+https://github.com/nikitadurasov/torch-ttt.git</span>
</span></code></pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span><code><span id="line-1">Uncomment the line below to install torch-ttt if you're running this in Colab
</span></code></pre></div>
</div>
<section id="helper-functions">
<h2>Helper Functions<a @click.prevent="window.navigator.clipboard.writeText($el.href); $el.setAttribute('data-tooltip', 'Copied!'); setTimeout(() =&gt; $el.setAttribute('data-tooltip', 'Copy link to this element'), 2000)" aria-label="Copy link to this element" class="headerlink" data-tooltip="Copy link to this element" href="#helper-functions" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#helper-functions'"><span>#</span></a></h2>
<section id="data-preparation">
<h3>Data Preparation<a @click.prevent="window.navigator.clipboard.writeText($el.href); $el.setAttribute('data-tooltip', 'Copied!'); setTimeout(() =&gt; $el.setAttribute('data-tooltip', 'Copy link to this element'), 2000)" aria-label="Copy link to this element" class="headerlink" data-tooltip="Copy link to this element" href="#data-preparation" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#data-preparation'"><span>#</span></a></h3>
<p>We will work with the ImageNet dataset, using both the clean validation set and the corrupted validation set from <a class="reference external" href="https://github.com/hendrycks/robustness">ImageNet-C</a>. The corrupted version includes various types of distortions, such as noise, blur, and weather effects. For this tutorial, weâ€™ll focus on a single corruption type: pixelation.</p>
<p>Letâ€™s start by downloading both the clean and corrupted versions of the ImageNet validation set.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
</span><span id="line-2">
</span><span id="line-3"><span class="c1"># Download and extract clean ImageNet validation set</span>
</span><span id="line-4"><span class="n">os</span><span class="o">.</span><span class="n">system</span><span class="p">(</span><span class="s2">"gdown 1Q6wQbNZMF0XdopzQGePDQAqVusMpbKxI &amp;&amp; tar -xzf imagenet_clean.tar.gz"</span><span class="p">)</span>
</span><span id="line-5">
</span><span id="line-6"><span class="c1"># Download and extract corrupted ImageNet validation set</span>
</span><span id="line-7"><span class="n">os</span><span class="o">.</span><span class="n">system</span><span class="p">(</span><span class="s2">"gdown 1AeMUO_6M0F0E7AOBxpb97svMXAwjtyXf &amp;&amp; tar -xzf imagenet_corrupted.tar.gz"</span><span class="p">)</span>
</span></code></pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span><code><span id="line-1">0
</span></code></pre></div>
</div>
<p>â€¦ and importing the necessary libraries.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="line-2"><span class="kn">import</span><span class="w"> </span><span class="nn">torchvision.datasets</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">datasets</span>
</span><span id="line-3"><span class="kn">import</span><span class="w"> </span><span class="nn">torchvision.transforms</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">transforms</span>
</span><span id="line-4"><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
</span><span id="line-5"><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>
</span><span id="line-6"><span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
</span><span id="line-7"><span class="kn">import</span><span class="w"> </span><span class="nn">json</span>
</span><span id="line-8"><span class="kn">import</span><span class="w"> </span><span class="nn">urllib.request</span>
</span><span id="line-9"><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
</span><span id="line-10"><span class="kn">from</span><span class="w"> </span><span class="nn">torchvision</span><span class="w"> </span><span class="kn">import</span> <span class="n">models</span>
</span><span id="line-11"><span class="kn">from</span><span class="w"> </span><span class="nn">torchvision.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">resnet50</span><span class="p">,</span> <span class="n">ResNet50_Weights</span>
</span><span id="line-12">
</span><span id="line-13"><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">'TORCH_HOME'</span><span class="p">]</span> <span class="o">=</span> <span class="s1">'./weights'</span>
</span><span id="line-14"><span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">'TORCH_HOME'</span><span class="p">],</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="line-15">
</span><span id="line-16"><span class="c1"># sphinx_gallery_thumbnail_path = '_static/images/examples/imagenet_corrupted.png'</span>
</span></code></pre></div>
</div>
</section>
<section id="utility-classes">
<h3>Utility Classes<a @click.prevent="window.navigator.clipboard.writeText($el.href); $el.setAttribute('data-tooltip', 'Copied!'); setTimeout(() =&gt; $el.setAttribute('data-tooltip', 'Copy link to this element'), 2000)" aria-label="Copy link to this element" class="headerlink" data-tooltip="Copy link to this element" href="#utility-classes" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#utility-classes'"><span>#</span></a></h3>
<p>Later in the tutorial, we will use the following helper classes and functions to track and visualize the progress of our model evaluation on both the clean and corrupted versions of ImageNet, allowing us to observe the differences in performance.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="k">class</span><span class="w"> </span><span class="nc">AverageMeter</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
</span><span id="line-2">    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">':f'</span><span class="p">):</span>
</span><span id="line-3">        <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>
</span><span id="line-4">        <span class="bp">self</span><span class="o">.</span><span class="n">fmt</span> <span class="o">=</span> <span class="n">fmt</span>
</span><span id="line-5">        <span class="bp">self</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
</span><span id="line-6">
</span><span id="line-7">    <span class="k">def</span><span class="w"> </span><span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="line-8">        <span class="bp">self</span><span class="o">.</span><span class="n">val</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="line-9">        <span class="bp">self</span><span class="o">.</span><span class="n">avg</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="line-10">        <span class="bp">self</span><span class="o">.</span><span class="n">sum</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="line-11">        <span class="bp">self</span><span class="o">.</span><span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="line-12">
</span><span id="line-13">    <span class="k">def</span><span class="w"> </span><span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
</span><span id="line-14">        <span class="bp">self</span><span class="o">.</span><span class="n">val</span> <span class="o">=</span> <span class="n">val</span>
</span><span id="line-15">        <span class="bp">self</span><span class="o">.</span><span class="n">sum</span> <span class="o">+=</span> <span class="n">val</span> <span class="o">*</span> <span class="n">n</span>
</span><span id="line-16">        <span class="bp">self</span><span class="o">.</span><span class="n">count</span> <span class="o">+=</span> <span class="n">n</span>
</span><span id="line-17">        <span class="bp">self</span><span class="o">.</span><span class="n">avg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sum</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">count</span>
</span><span id="line-18">
</span><span id="line-19">    <span class="k">def</span><span class="w"> </span><span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="line-20">        <span class="n">fmtstr</span> <span class="o">=</span> <span class="s1">'</span><span class="si">{name}</span><span class="s1"> {val'</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">fmt</span> <span class="o">+</span> <span class="s1">'} ({avg'</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">fmt</span> <span class="o">+</span> <span class="s1">'})'</span>
</span><span id="line-21">        <span class="k">return</span> <span class="n">fmtstr</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">)</span>
</span><span id="line-22">
</span><span id="line-23"><span class="k">class</span><span class="w"> </span><span class="nc">ProgressMeter</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
</span><span id="line-24">    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_batches</span><span class="p">,</span> <span class="n">meters</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s2">""</span><span class="p">):</span>
</span><span id="line-25">        <span class="bp">self</span><span class="o">.</span><span class="n">batch_fmtstr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_batch_fmtstr</span><span class="p">(</span><span class="n">num_batches</span><span class="p">)</span>
</span><span id="line-26">        <span class="bp">self</span><span class="o">.</span><span class="n">meters</span> <span class="o">=</span> <span class="n">meters</span>
</span><span id="line-27">        <span class="bp">self</span><span class="o">.</span><span class="n">prefix</span> <span class="o">=</span> <span class="n">prefix</span>
</span><span id="line-28">
</span><span id="line-29">    <span class="k">def</span><span class="w"> </span><span class="nf">display</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
</span><span id="line-30">        <span class="n">entries</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">prefix</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_fmtstr</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">batch</span><span class="p">)]</span>
</span><span id="line-31">        <span class="n">entries</span> <span class="o">+=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">meter</span><span class="p">)</span> <span class="k">for</span> <span class="n">meter</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">meters</span><span class="p">]</span>
</span><span id="line-32">        <span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\t</span><span class="s1">'</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">entries</span><span class="p">))</span>
</span><span id="line-33">
</span><span id="line-34">    <span class="k">def</span><span class="w"> </span><span class="nf">display_summary</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="line-35">        <span class="n">entries</span> <span class="o">=</span> <span class="p">[</span><span class="s2">" *"</span><span class="p">]</span>
</span><span id="line-36">        <span class="n">entries</span> <span class="o">+=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">meter</span><span class="p">)</span> <span class="k">for</span> <span class="n">meter</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">meters</span><span class="p">]</span>
</span><span id="line-37">        <span class="nb">print</span><span class="p">(</span><span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">entries</span><span class="p">))</span>
</span><span id="line-38">
</span><span id="line-39">    <span class="k">def</span><span class="w"> </span><span class="nf">_get_batch_fmtstr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_batches</span><span class="p">):</span>
</span><span id="line-40">        <span class="n">num_digits</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">num_batches</span> <span class="o">//</span> <span class="mi">1</span><span class="p">))</span>
</span><span id="line-41">        <span class="n">fmt</span> <span class="o">=</span> <span class="s1">'{:'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">num_digits</span><span class="p">)</span> <span class="o">+</span> <span class="s1">'d}'</span>
</span><span id="line-42">        <span class="k">return</span> <span class="s1">'['</span> <span class="o">+</span> <span class="n">fmt</span> <span class="o">+</span> <span class="s1">'/'</span> <span class="o">+</span> <span class="n">fmt</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">num_batches</span><span class="p">)</span> <span class="o">+</span> <span class="s1">']'</span>
</span><span id="line-43">
</span><span id="line-44"><span class="c1"># Human-readable labels</span>
</span><span id="line-45"><span class="n">synset_to_name</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlopen</span><span class="p">(</span>
</span><span id="line-46">    <span class="s2">"https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json"</span>
</span><span id="line-47"><span class="p">))</span>
</span><span id="line-48"><span class="n">human_readable_labels</span> <span class="o">=</span> <span class="n">synset_to_name</span>
</span><span id="line-49">
</span><span id="line-50">
</span><span id="line-51"><span class="k">def</span><span class="w"> </span><span class="nf">visualize_samples</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
</span><span id="line-52"><span class="w">    </span><span class="sd">"""Visualize a few samples from the dataset and return the plot."""</span>
</span><span id="line-53">    <span class="n">mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">])</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
</span><span id="line-54">    <span class="n">std</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
</span><span id="line-55">
</span><span id="line-56">    <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">dataset</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">//</span> <span class="mi">15</span><span class="p">)])</span>
</span><span id="line-57">    <span class="n">images</span> <span class="o">=</span> <span class="p">[</span><span class="n">img</span> <span class="o">*</span> <span class="n">std</span> <span class="o">+</span> <span class="n">mean</span> <span class="k">for</span> <span class="n">img</span> <span class="ow">in</span> <span class="n">images</span><span class="p">]</span>
</span><span id="line-58">
</span><span id="line-59">    <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
</span><span id="line-60">    <span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">img</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axes</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
</span><span id="line-61">        <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</span><span id="line-62">        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">human_readable_labels</span><span class="p">[</span><span class="n">label</span><span class="p">],</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
</span><span id="line-63">        <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'off'</span><span class="p">)</span>
</span><span id="line-64">    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</span><span id="line-65">    <span class="k">return</span> <span class="n">fig</span>
</span></code></pre></div>
</div>
</section>
<section id="accuracy-and-validation-function">
<h3>Accuracy and Validation Function<a @click.prevent="window.navigator.clipboard.writeText($el.href); $el.setAttribute('data-tooltip', 'Copied!'); setTimeout(() =&gt; $el.setAttribute('data-tooltip', 'Copy link to this element'), 2000)" aria-label="Copy link to this element" class="headerlink" data-tooltip="Copy link to this element" href="#accuracy-and-validation-function" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#accuracy-and-validation-function'"><span>#</span></a></h3>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="k">def</span><span class="w"> </span><span class="nf">accuracy</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">topk</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,)):</span>
</span><span id="line-2">    <span class="n">maxk</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">topk</span><span class="p">)</span>
</span><span id="line-3">    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span><span id="line-4">
</span><span id="line-5">    <span class="n">_</span><span class="p">,</span> <span class="n">pred</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">maxk</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
</span><span id="line-6">    <span class="n">pred</span> <span class="o">=</span> <span class="n">pred</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>
</span><span id="line-7">    <span class="n">correct</span> <span class="o">=</span> <span class="n">pred</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand_as</span><span class="p">(</span><span class="n">pred</span><span class="p">))</span>
</span><span id="line-8">
</span><span id="line-9">    <span class="n">res</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="line-10">    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">topk</span><span class="p">:</span>
</span><span id="line-11">        <span class="n">correct_k</span> <span class="o">=</span> <span class="n">correct</span><span class="p">[:</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="line-12">        <span class="n">res</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">correct_k</span><span class="o">.</span><span class="n">mul_</span><span class="p">(</span><span class="mf">100.0</span> <span class="o">/</span> <span class="n">batch_size</span><span class="p">))</span>
</span><span id="line-13">    <span class="k">return</span> <span class="n">res</span>
</span><span id="line-14">
</span><span id="line-15"><span class="k">def</span><span class="w"> </span><span class="nf">validate</span><span class="p">(</span><span class="n">val_loader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">ttt</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
</span><span id="line-16">    <span class="n">batch_time</span> <span class="o">=</span> <span class="n">AverageMeter</span><span class="p">(</span><span class="s1">'Time'</span><span class="p">,</span> <span class="s1">':6.3f'</span><span class="p">)</span>
</span><span id="line-17">    <span class="n">losses</span> <span class="o">=</span> <span class="n">AverageMeter</span><span class="p">(</span><span class="s1">'Loss'</span><span class="p">,</span> <span class="s1">':.4e'</span><span class="p">)</span>
</span><span id="line-18">    <span class="n">top1</span> <span class="o">=</span> <span class="n">AverageMeter</span><span class="p">(</span><span class="s1">'Acc@1'</span><span class="p">,</span> <span class="s1">':6.2f'</span><span class="p">)</span>
</span><span id="line-19">    <span class="n">top5</span> <span class="o">=</span> <span class="n">AverageMeter</span><span class="p">(</span><span class="s1">'Acc@5'</span><span class="p">,</span> <span class="s1">':6.2f'</span><span class="p">)</span>
</span><span id="line-20">    <span class="n">progress</span> <span class="o">=</span> <span class="n">ProgressMeter</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">val_loader</span><span class="p">),</span> <span class="p">[</span><span class="n">batch_time</span><span class="p">,</span> <span class="n">losses</span><span class="p">,</span> <span class="n">top1</span><span class="p">,</span> <span class="n">top5</span><span class="p">],</span> <span class="n">prefix</span><span class="o">=</span><span class="s1">'Test: '</span><span class="p">)</span>
</span><span id="line-21">
</span><span id="line-22">    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</span><span id="line-23">    <span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
</span><span id="line-24">
</span><span id="line-25">    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">val_loader</span><span class="p">):</span>
</span><span id="line-26">        <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span><span id="line-27">        <span class="n">target</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span><span id="line-28">
</span><span id="line-29">        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">ttt</span> <span class="k">else</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
</span><span id="line-30">        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
</span><span id="line-31">
</span><span id="line-32">        <span class="n">acc1</span><span class="p">,</span> <span class="n">acc5</span> <span class="o">=</span> <span class="n">accuracy</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">topk</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
</span><span id="line-33">        <span class="n">losses</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">images</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
</span><span id="line-34">        <span class="n">top1</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">acc1</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">images</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
</span><span id="line-35">        <span class="n">top5</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">acc5</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">images</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
</span><span id="line-36">
</span><span id="line-37">        <span class="n">batch_time</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">end</span><span class="p">)</span>
</span><span id="line-38">        <span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
</span><span id="line-39">
</span><span id="line-40">        <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="line-41">            <span class="n">progress</span><span class="o">.</span><span class="n">display</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="line-42">
</span><span id="line-43">    <span class="n">progress</span><span class="o">.</span><span class="n">display_summary</span><span class="p">()</span>
</span><span id="line-44">    <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">top1</span><span class="o">.</span><span class="n">avg</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span></code></pre></div>
</div>
</section>
</section>
<section id="clean-data-evaluation">
<h2>Clean Data Evaluation<a @click.prevent="window.navigator.clipboard.writeText($el.href); $el.setAttribute('data-tooltip', 'Copied!'); setTimeout(() =&gt; $el.setAttribute('data-tooltip', 'Copy link to this element'), 2000)" aria-label="Copy link to this element" class="headerlink" data-tooltip="Copy link to this element" href="#clean-data-evaluation" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#clean-data-evaluation'"><span>#</span></a></h2>
<section id="clean-imagenet-validation-set">
<h3>Clean ImageNet Validation Set<a @click.prevent="window.navigator.clipboard.writeText($el.href); $el.setAttribute('data-tooltip', 'Copied!'); setTimeout(() =&gt; $el.setAttribute('data-tooltip', 'Copy link to this element'), 2000)" aria-label="Copy link to this element" class="headerlink" data-tooltip="Copy link to this element" href="#clean-imagenet-validation-set" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#clean-imagenet-validation-set'"><span>#</span></a></h3>
<p>First, letâ€™s take a look at the clean validation set. Weâ€™ll visualize a few sample images. As you can see, the images are clear, and itâ€™s relatively easy to recognize the objects they depict.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
</span><span id="line-2">    <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span>
</span><span id="line-3">    <span class="n">transforms</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
</span><span id="line-4">    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
</span><span id="line-5">    <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])</span>
</span><span id="line-6"><span class="p">])</span>
</span><span id="line-7">
</span><span id="line-8"><span class="n">val_dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">ImageFolder</span><span class="p">(</span><span class="s2">"./imagenet_clean"</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>
</span><span id="line-9"><span class="n">val_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">val_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="line-10">
</span><span id="line-11"><span class="n">visualize_samples</span><span class="p">(</span><span class="n">val_dataset</span><span class="p">)</span>
</span></code></pre></div>
</div>
<img alt="tench, Saharan horned viper, bittern, Scottish Terrier, Miniature Poodle, hamster, abaya, high-speed train, dining table, honeycomb, mortar, Polaroid camera, sliding door, toy store, pretzel" class="sphx-glr-single-img" src="../_images/sphx_glr_02_imagenet_tent_001.png" srcset="../_images/sphx_glr_02_imagenet_tent_001.png"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span><code><span id="line-1">&lt;Figure size 1200x700 with 15 Axes&gt;
</span></code></pre></div>
</div>
</section>
<section id="pretrained-model-evaluation-on-clean-data">
<h3>Pretrained Model Evaluation on Clean Data<a @click.prevent="window.navigator.clipboard.writeText($el.href); $el.setAttribute('data-tooltip', 'Copied!'); setTimeout(() =&gt; $el.setAttribute('data-tooltip', 'Copy link to this element'), 2000)" aria-label="Copy link to this element" class="headerlink" data-tooltip="Copy link to this element" href="#pretrained-model-evaluation-on-clean-data" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#pretrained-model-evaluation-on-clean-data'"><span>#</span></a></h3>
<p>Now, letâ€™s load a pretrained ResNet-50 model and evaluate its performance on the clean validation set. Weâ€™ll use the <cite>torchvision</cite> library to load the model. The resulting accuracy, around 77%, aligns with the official accuracy reported by torchvision.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="n">device</span> <span class="o">=</span> <span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span>
</span><span id="line-2"><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span><span id="line-3"><span class="n">model</span> <span class="o">=</span> <span class="n">resnet50</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">ResNet50_Weights</span><span class="o">.</span><span class="n">IMAGENET1K_V1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span><span id="line-4"><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</span><span id="line-5">
</span><span id="line-6"><span class="n">acc_clean</span> <span class="o">=</span> <span class="n">validate</span><span class="p">(</span><span class="n">val_loader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
</span><span id="line-7"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Clean Accuracy: </span><span class="si">{</span><span class="n">acc_clean</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
</span></code></pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span><code><span id="line-1">/scratch/cvlab/home/durasov/miniconda/envs/torch_ttt/lib/python3.10/site-packages/torch/hub.py:846: UserWarning: TORCH_MODEL_ZOO is deprecated, please use env TORCH_HOME instead
</span><span id="line-2">  warnings.warn(
</span><span id="line-3">Test: [  1/157] Time  1.066 ( 1.066)    Loss 1.0837e+00 (1.0837e+00)    Acc@1  71.88 ( 71.88)   Acc@5  96.88 ( 96.88)
</span><span id="line-4">Test: [101/157] Time  0.053 ( 0.063)    Loss 1.2988e+00 (9.5816e-01)    Acc@1  65.62 ( 76.61)   Acc@5  90.62 ( 93.35)
</span><span id="line-5"> * Time  0.013 ( 0.060) Loss 1.6625e-01 (9.2224e-01) Acc@1 100.00 ( 77.32) Acc@5 100.00 ( 93.36)
</span><span id="line-6">Clean Accuracy: 77.32%
</span></code></pre></div>
</div>
</section>
</section>
<section id="corrupted-data-evaluation">
<h2>Corrupted Data Evaluation<a @click.prevent="window.navigator.clipboard.writeText($el.href); $el.setAttribute('data-tooltip', 'Copied!'); setTimeout(() =&gt; $el.setAttribute('data-tooltip', 'Copy link to this element'), 2000)" aria-label="Copy link to this element" class="headerlink" data-tooltip="Copy link to this element" href="#corrupted-data-evaluation" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#corrupted-data-evaluation'"><span>#</span></a></h2>
<section id="corrupted-imagenet-validation-set">
<h3>Corrupted ImageNet Validation Set<a @click.prevent="window.navigator.clipboard.writeText($el.href); $el.setAttribute('data-tooltip', 'Copied!'); setTimeout(() =&gt; $el.setAttribute('data-tooltip', 'Copy link to this element'), 2000)" aria-label="Copy link to this element" class="headerlink" data-tooltip="Copy link to this element" href="#corrupted-imagenet-validation-set" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#corrupted-imagenet-validation-set'"><span>#</span></a></h3>
<p>Now, letâ€™s take a look at the corrupted validation set. Weâ€™ll visualize a few sample images as well. As you can see, the images are distorted, making it more difficult to recognize the objects they contain. In this example, we use pixelated images as the corruption type, which, as weâ€™ll see, has a significant impact on the modelâ€™s performance.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="n">corrupted_dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">ImageFolder</span><span class="p">(</span><span class="s2">"./imagenet_corrupted"</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>
</span><span id="line-2"><span class="n">corrupted_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">corrupted_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="line-3">
</span><span id="line-4"><span class="n">visualize_samples</span><span class="p">(</span><span class="n">corrupted_dataset</span><span class="p">)</span>
</span></code></pre></div>
</div>
<img alt="tench, Saharan horned viper, bittern, Scottish Terrier, Miniature Poodle, hamster, abaya, high-speed train, dining table, honeycomb, mortar, Polaroid camera, sliding door, toy store, pretzel" class="sphx-glr-single-img" src="../_images/sphx_glr_02_imagenet_tent_002.png" srcset="../_images/sphx_glr_02_imagenet_tent_002.png"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span><code><span id="line-1">&lt;Figure size 1200x700 with 15 Axes&gt;
</span></code></pre></div>
</div>
</section>
<section id="pretrained-model-evaluation-on-corrupted-data">
<h3>Pretrained Model Evaluation on Corrupted Data<a @click.prevent="window.navigator.clipboard.writeText($el.href); $el.setAttribute('data-tooltip', 'Copied!'); setTimeout(() =&gt; $el.setAttribute('data-tooltip', 'Copy link to this element'), 2000)" aria-label="Copy link to this element" class="headerlink" data-tooltip="Copy link to this element" href="#pretrained-model-evaluation-on-corrupted-data" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#pretrained-model-evaluation-on-corrupted-data'"><span>#</span></a></h3>
<p>Letâ€™s evaluate the pretrained model on the corrupted validation set. As expected, the accuracy drops significantlyâ€”from 77% to around 20%â€”indicating that the model struggles to recognize objects in distorted images.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="n">acc_corrupted</span> <span class="o">=</span> <span class="n">validate</span><span class="p">(</span><span class="n">corrupted_loader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
</span><span id="line-2"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Corrupted Accuracy: </span><span class="si">{</span><span class="n">acc_corrupted</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
</span></code></pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span><code><span id="line-1">Test: [  1/157] Time  0.469 ( 0.469)    Loss 3.4536e+00 (3.4536e+00)    Acc@1  28.12 ( 28.12)   Acc@5  53.12 ( 53.12)
</span><span id="line-2">Test: [101/157] Time  0.053 ( 0.058)    Loss 3.5986e+00 (4.3267e+00)    Acc@1  34.38 ( 23.08)   Acc@5  56.25 ( 43.44)
</span><span id="line-3"> * Time  0.013 ( 0.056) Loss 4.9279e+00 (4.3666e+00) Acc@1  25.00 ( 22.70) Acc@5  25.00 ( 43.08)
</span><span id="line-4">Corrupted Accuracy: 22.70%
</span></code></pre></div>
</div>
</section>
</section>
<section id="optimized-inference-with-torch-ttt">
<h2>Optimized Inference with torch-ttt<a @click.prevent="window.navigator.clipboard.writeText($el.href); $el.setAttribute('data-tooltip', 'Copied!'); setTimeout(() =&gt; $el.setAttribute('data-tooltip', 'Copy link to this element'), 2000)" aria-label="Copy link to this element" class="headerlink" data-tooltip="Copy link to this element" href="#optimized-inference-with-torch-ttt" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#optimized-inference-with-torch-ttt'"><span>#</span></a></h2>
<section id="test-time-adaptation-with-tent">
<h3>Test-Time Adaptation with Tent<a @click.prevent="window.navigator.clipboard.writeText($el.href); $el.setAttribute('data-tooltip', 'Copied!'); setTimeout(() =&gt; $el.setAttribute('data-tooltip', 'Copy link to this element'), 2000)" aria-label="Copy link to this element" class="headerlink" data-tooltip="Copy link to this element" href="#test-time-adaptation-with-tent" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#test-time-adaptation-with-tent'"><span>#</span></a></h3>
<p>As weâ€™ve seen, image corruptions can significantly degrade model performance. To tackle this issue, we can use test-time adaptation techniques. In this example, weâ€™ll demonstrate how to apply <strong>TENT</strong> (Test-time Entropy Minimization), which adapts the model to the input data during inference.</p>
<p>TENT works by minimizing the entropy of the modelâ€™s predictions, encouraging more confident outputs. During inference, the model produces a probability distribution over the classes. TENT computes the entropy of this distribution, then calculates gradients with respect to the parameters of the normalization layers (e.g., BatchNorm) and updates their affine parameters accordingly. This adaptation is performed for a set number of steps, allowing the model to better align with the current input distribution.</p>
<p>Using TENT with <a class="reference external" href="https://github.com/nikitadurasov/torch-ttt">torch-ttt</a> is straightforward: simply create a <cite>TentEngine</cite> instance and provide it with the model and optimization parameters such as the learning rate and number of adaptation steps. Even with just a single adaptation step, we observe a notable improvement in accuracyâ€”about 10%â€”on corrupted ImageNet data compared to the original pretrained ResNet-50. Further tuning of the optimization parameters can lead to even better results.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="kn">from</span><span class="w"> </span><span class="nn">torch_ttt.engine.tent_engine</span><span class="w"> </span><span class="kn">import</span> <span class="n">TentEngine</span>
</span><span id="line-2">
</span><span id="line-3"><span class="n">engine</span> <span class="o">=</span> <span class="n">TentEngine</span><span class="p">(</span>
</span><span id="line-4">    <span class="n">model</span><span class="p">,</span>
</span><span id="line-5">    <span class="n">optimization_parameters</span><span class="o">=</span><span class="p">{</span>
</span><span id="line-6">        <span class="s2">"lr"</span><span class="p">:</span> <span class="mf">2e-3</span><span class="p">,</span>
</span><span id="line-7">        <span class="s2">"num_steps"</span><span class="p">:</span> <span class="mi">1</span>
</span><span id="line-8">    <span class="p">}</span>
</span><span id="line-9"><span class="p">)</span>
</span><span id="line-10"><span class="n">engine</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</span><span id="line-11">
</span><span id="line-12"><span class="n">acc_tent</span> <span class="o">=</span> <span class="n">validate</span><span class="p">(</span><span class="n">corrupted_loader</span><span class="p">,</span> <span class="n">engine</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">ttt</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="line-13"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Corrupted Accuracy with Tent: </span><span class="si">{</span><span class="n">acc_tent</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
</span></code></pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span><code><span id="line-1">Test: [  1/157] Time  0.648 ( 0.648)    Loss 7.0112e+00 (7.0112e+00)    Acc@1  25.00 ( 25.00)   Acc@5  40.62 ( 40.62)
</span><span id="line-2">Test: [101/157] Time  0.194 ( 0.199)    Loss 3.1544e+00 (5.0462e+00)    Acc@1  46.88 ( 31.65)   Acc@5  78.12 ( 55.26)
</span><span id="line-3"> * Time  0.062 ( 0.196) Loss 8.7884e+00 (5.0529e+00) Acc@1  12.50 ( 31.24) Acc@5  12.50 ( 54.72)
</span><span id="line-4">Corrupted Accuracy with Tent: 31.24%
</span></code></pre></div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (1 minutes 53.144 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-02-imagenet-tent-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/2f6c58ddee2df5b620a9183241196203/02_imagenet_tent.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">02_imagenet_tent.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/643c6ff6a8567fb1cc2106ce09d41d86/02_imagenet_tent.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">02_imagenet_tent.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../_downloads/11fca63ef7de0814887078d9fb2eb6af/02_imagenet_tent.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">02_imagenet_tent.zip</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>
</section>
</div><div class="flex justify-between items-center pt-6 mt-12 border-t border-border gap-4">
<div class="mr-auto">
<a class="inline-flex items-center justify-center rounded-md text-sm font-medium transition-colors border border-input hover:bg-accent hover:text-accent-foreground py-2 px-4" href="01_mnist_TTT.html">
<svg class="mr-2 h-4 w-4" fill="none" height="24" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
<polyline points="15 18 9 12 15 6"></polyline>
</svg>
        TTT for Corrupted MNIST
      </a>
</div>
<div class="ml-auto">
<a class="inline-flex items-center justify-center rounded-md text-sm font-medium transition-colors border border-input hover:bg-accent hover:text-accent-foreground py-2 px-4" href="../api.html">
        API Reference
        <svg class="ml-2 h-4 w-4" fill="none" height="24" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
<polyline points="9 18 15 12 9 6"></polyline>
</svg>
</a>
</div>
</div></div><aside class="hidden text-sm xl:block" id="right-sidebar">
<div class="sticky top-16 -mt-10 max-h-[calc(100vh-5rem)] h-full overflow-y-auto pt-6 space-y-2"><p class="font-medium">On this page</p>
<ul>
<li><a :data-current="activeSection === '#helper-functions'" class="reference internal" href="#helper-functions">Helper Functions</a><ul>
<li><a :data-current="activeSection === '#data-preparation'" class="reference internal" href="#data-preparation">Data Preparation</a></li>
<li><a :data-current="activeSection === '#utility-classes'" class="reference internal" href="#utility-classes">Utility Classes</a></li>
<li><a :data-current="activeSection === '#accuracy-and-validation-function'" class="reference internal" href="#accuracy-and-validation-function">Accuracy and Validation Function</a></li>
</ul>
</li>
<li><a :data-current="activeSection === '#clean-data-evaluation'" class="reference internal" href="#clean-data-evaluation">Clean Data Evaluation</a><ul>
<li><a :data-current="activeSection === '#clean-imagenet-validation-set'" class="reference internal" href="#clean-imagenet-validation-set">Clean ImageNet Validation Set</a></li>
<li><a :data-current="activeSection === '#pretrained-model-evaluation-on-clean-data'" class="reference internal" href="#pretrained-model-evaluation-on-clean-data">Pretrained Model Evaluation on Clean Data</a></li>
</ul>
</li>
<li><a :data-current="activeSection === '#corrupted-data-evaluation'" class="reference internal" href="#corrupted-data-evaluation">Corrupted Data Evaluation</a><ul>
<li><a :data-current="activeSection === '#corrupted-imagenet-validation-set'" class="reference internal" href="#corrupted-imagenet-validation-set">Corrupted ImageNet Validation Set</a></li>
<li><a :data-current="activeSection === '#pretrained-model-evaluation-on-corrupted-data'" class="reference internal" href="#pretrained-model-evaluation-on-corrupted-data">Pretrained Model Evaluation on Corrupted Data</a></li>
</ul>
</li>
<li><a :data-current="activeSection === '#optimized-inference-with-torch-ttt'" class="reference internal" href="#optimized-inference-with-torch-ttt">Optimized Inference with torch-ttt</a><ul>
<li><a :data-current="activeSection === '#test-time-adaptation-with-tent'" class="reference internal" href="#test-time-adaptation-with-tent">Test-Time Adaptation with Tent</a></li>
</ul>
</li>
</ul>
</div>
</aside>
</main>
</div>
</div><footer class="py-6 border-t border-border md:py-0">
<div class="container flex flex-col items-center justify-between gap-4 md:h-24 md:flex-row">
<div class="flex flex-col items-center gap-4 px-8 md:flex-row md:gap-2 md:px-0">
<p class="text-sm leading-loose text-center text-muted-foreground md:text-left">Â© 2024, Nikita DurasovÂ Built with <a class="font-medium underline underline-offset-4" href="https://www.sphinx-doc.org" rel="noreferrer">Sphinx 8.1.3</a></p>
</div>
</div>
</footer>
</div>
<script src="../_static/documentation_options.js?v=5929fcd5"></script>
<script src="../_static/doctools.js?v=9bcbadda"></script>
<script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
<script defer="defer" src="../_static/theme.js?v=e14a7d8a"></script>
<script src="../_static/js/theme.js?v=f24de042"></script>
</body>
</html>