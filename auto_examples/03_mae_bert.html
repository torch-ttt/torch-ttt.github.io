<!DOCTYPE html>

<html data-content_root="../" lang="en" x-data="{activeSection: ''}">
<head>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<meta charset="utf-8"/>
<meta content="#ffffff" media="(prefers-color-scheme: light)" name="theme-color"/>
<meta content="#030711" media="(prefers-color-scheme: dark)" name="theme-color"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>

<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-NRNXK42JKJ"></script>
<script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-NRNXK42JKJ');
    </script>
<title>Test-Time Training for Corrupted WILDS Dataset | torch-ttt</title>
<meta content="Test-Time Training for Corrupted WILDS Dataset | torch&lt;span style='border-radius: 4px; color: white; text-justify: none; padding: 0px 2px 0px 2px; background: linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3)); -moz-linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3)); -webkit-linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3));'&gt;-ttt&lt;/span&gt;" property="og:title"/>
<meta content="Test-Time Training for Corrupted WILDS Dataset | torch&lt;span style='border-radius: 4px; color: white; text-justify: none; padding: 0px 2px 0px 2px; background: linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3)); -moz-linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3)); -webkit-linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3));'&gt;-ttt&lt;/span&gt;" name="twitter:title"/>
<link href="../_static/pygments.css?v=82fa1eaf" rel="stylesheet" type="text/css"/>
<link href="../_static/theme.css?v=c0d22bf5" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery.css?v=d2d258e8" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-binder.css?v=f4aeca0c" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-dataframe.css?v=2082cf3c" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" rel="stylesheet" type="text/css"/>
<link href="../_static/css/custom.css?v=f0970611" rel="stylesheet" type="text/css"/>
<link href="../_static/css/docstring_custom.css?v=c7bea3a5" rel="stylesheet" type="text/css"/>
<link href="../_static/torch-ttt.svg" rel="icon"/>
<link href="../search.html" rel="search" title="Search"/>
<link href="../genindex.html" rel="index" title="Index"/>
<link href="../papers.html" rel="next" title="Papers"/>
<link href="02_imagenet_tent.html" rel="prev" title="ImageNet Robustness with TENT"/>
</head>
<body :class="{ 'overflow-hidden': showSidebar }" class="min-h-screen font-sans antialiased bg-background text-foreground" x-data="{ showSidebar: false, showScrollTop: false }">
<div @click.self="showSidebar = false" class="fixed inset-0 z-50 overflow-hidden bg-background/80 backdrop-blur-sm md:hidden" x-cloak="" x-show="showSidebar"></div><div class="relative flex flex-col min-h-screen" id="page"><a class="absolute top-0 left-0 z-[100] block bg-background p-4 text-xl transition -translate-x-full opacity-0 focus:translate-x-0 focus:opacity-100" href="#content">
      Skip to content
    </a><header class="sticky top-0 z-40 w-full border-b shadow-sm border-border bg-background/90 backdrop-blur"><div class="container flex items-center h-14">
<div class="hidden mr-4 md:flex">
<a class="flex items-center mr-6" href="../index.html">
<img alt="Logo" class="mr-2 dark:invert" height="24" src="../_static/torch-ttt.svg" width="24"/><span class="hidden font-bold sm:inline-block text-clip whitespace-nowrap">torch<span style="border-radius: 4px; color: white; text-justify: none; padding: 0px 2px 0px 2px; background: linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3)); -moz-linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3)); -webkit-linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3));">-ttt</span></span>
</a></div><button @click="showSidebar = true" class="inline-flex items-center justify-center h-10 px-0 py-2 mr-2 text-base font-medium transition-colors rounded-md hover:text-accent-foreground hover:bg-transparent md:hidden" type="button">
<svg aria-hidden="true" fill="currentColor" height="24" viewbox="0 96 960 960" width="24" xmlns="http://www.w3.org/2000/svg">
<path d="M152.587 825.087q-19.152 0-32.326-13.174t-13.174-32.326q0-19.152 13.174-32.326t32.326-13.174h440q19.152 0 32.326 13.174t13.174 32.326q0 19.152-13.174 32.326t-32.326 13.174h-440Zm0-203.587q-19.152 0-32.326-13.174T107.087 576q0-19.152 13.174-32.326t32.326-13.174h320q19.152 0 32.326 13.174T518.087 576q0 19.152-13.174 32.326T472.587 621.5h-320Zm0-203.587q-19.152 0-32.326-13.174t-13.174-32.326q0-19.152 13.174-32.326t32.326-13.174h440q19.152 0 32.326 13.174t13.174 32.326q0 19.152-13.174 32.326t-32.326 13.174h-440ZM708.913 576l112.174 112.174q12.674 12.674 12.674 31.826t-12.674 31.826Q808.413 764.5 789.261 764.5t-31.826-12.674l-144-144Q600 594.391 600 576t13.435-31.826l144-144q12.674-12.674 31.826-12.674t31.826 12.674q12.674 12.674 12.674 31.826t-12.674 31.826L708.913 576Z"></path>
</svg>
<span class="sr-only">Toggle navigation menu</span>
</button>
<div class="flex items-center justify-between flex-1 gap-2 sm:gap-4 md:justify-end">
<div class="flex-1 w-full md:w-auto md:flex-none"><form @keydown.k.window.meta="$refs.search.focus()" action="../search.html" class="relative flex items-center group" id="searchbox" method="get">
<input aria-label="Search the docs" class="inline-flex items-center font-medium transition-colors bg-transparent focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 ring-offset-background border border-input hover:bg-accent focus:bg-accent hover:text-accent-foreground focus:text-accent-foreground hover:placeholder-accent-foreground py-2 px-4 relative h-9 w-full justify-start rounded-[0.5rem] text-sm text-muted-foreground sm:pr-12 md:w-40 lg:w-64" id="search-input" name="q" placeholder="Search ..." type="search" x-ref="search"/>
<kbd class="pointer-events-none absolute right-1.5 top-2 hidden h-5 select-none text-muted-foreground items-center gap-1 rounded border border-border bg-muted px-1.5 font-mono text-[10px] font-medium opacity-100 sm:flex group-hover:bg-accent group-hover:text-accent-foreground">
<span class="text-xs">⌘</span>
    K
  </kbd>
</form>
</div>
<nav class="flex items-center gap-1">
<a href="https://github.com/nikitadurasov/torch-ttt" rel="noopener nofollow" title="Visit repository on GitHub">
<div class="inline-flex items-center justify-center px-0 text-sm font-medium transition-colors rounded-md hover:bg-accent hover:text-accent-foreground h-9 w-9">
<svg fill="currentColor" height="26px" style="margin-top:-2px;display:inline" viewbox="0 0 45 44" xmlns="http://www.w3.org/2000/svg"><path clip-rule="evenodd" d="M22.477.927C10.485.927.76 10.65.76 22.647c0 9.596 6.223 17.736 14.853 20.608 1.087.2 1.483-.47 1.483-1.047 0-.516-.019-1.881-.03-3.693-6.04 1.312-7.315-2.912-7.315-2.912-.988-2.51-2.412-3.178-2.412-3.178-1.972-1.346.149-1.32.149-1.32 2.18.154 3.327 2.24 3.327 2.24 1.937 3.318 5.084 2.36 6.321 1.803.197-1.403.759-2.36 1.379-2.903-4.823-.548-9.894-2.412-9.894-10.734 0-2.37.847-4.31 2.236-5.828-.224-.55-.969-2.759.214-5.748 0 0 1.822-.584 5.972 2.226 1.732-.482 3.59-.722 5.437-.732 1.845.01 3.703.25 5.437.732 4.147-2.81 5.967-2.226 5.967-2.226 1.185 2.99.44 5.198.217 5.748 1.392 1.517 2.232 3.457 2.232 5.828 0 8.344-5.078 10.18-9.916 10.717.779.67 1.474 1.996 1.474 4.021 0 2.904-.027 5.247-.027 5.96 0 .58.392 1.256 1.493 1.044C37.981 40.375 44.2 32.24 44.2 22.647c0-11.996-9.726-21.72-21.722-21.72" fill="currentColor" fill-rule="evenodd"></path></svg>
</div>
</a>
</nav>
</div>
</div>
</header>
<div class="flex-1"><div class="container md:grid md:grid-cols-[220px_minmax(0,1fr)] md:gap-6 lg:grid-cols-[240px_minmax(0,1fr)] lg:gap-10"><aside :aria-hidden="!showSidebar" :class="{ 'translate-x-0': showSidebar }" class="fixed inset-y-0 left-0 md:top-14 z-50 md:z-30 bg-background md:bg-transparent transition-all duration-100 -translate-x-full md:translate-x-0 ml-0 p-6 md:p-0 md:-ml-2 md:h-[calc(100vh-3.5rem)] w-5/6 md:w-full overflow-y-auto border-r border-border md:sticky" id="left-sidebar">
<a class="justify-start text-sm md:!hidden bg-background" href="../index.html">
<img alt="Logo" class="mr-2 dark:invert" height="16" src="../_static/torch-ttt.svg" width="16"/><span class="font-bold text-clip whitespace-nowrap">torch<span style="border-radius: 4px; color: white; text-justify: none; padding: 0px 2px 0px 2px; background: linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3)); -moz-linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3)); -webkit-linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3));">-ttt</span></span>
</a>
<div class="relative overflow-hidden md:overflow-auto my-4 md:my-0">
<div class="overflow-y-auto h-full w-full relative pr-6"><nav class="table w-full min-w-full my-6 lg:my-8">
<p class="caption" role="heading"><span class="caption-text">Getting Started:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quickstart.html">Quick Start</a></li>
<li class="toctree-l1 current" x-data="{ expanded: $el.classList.contains('current') ? true : false }"><a :class="{ 'expanded' : expanded }" @click="expanded = !expanded" class="reference internal expandable" href="index.html">Tutorials<button @click.prevent.stop="expanded = !expanded" type="button"><span class="sr-only"></span><svg fill="currentColor" height="18px" stroke="none" viewbox="0 0 24 24" width="18px" xmlns="http://www.w3.org/2000/svg"><path d="M10 6L8.59 7.41 13.17 12l-4.58 4.59L10 18l6-6z"></path></svg></button></a><ul class="current" x-show="expanded">
<li class="toctree-l2"><a class="reference internal" href="01_mnist_TTT.html">TTT for Corrupted MNIST</a></li>
<li class="toctree-l2"><a class="reference internal" href="02_imagenet_tent.html">ImageNet Robustness with TENT</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Test-Time Training for Corrupted WILDS Dataset</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../papers.html">Papers</a></li>
</ul>
</nav>
</div>
</div>
<button @click="showSidebar = false" class="absolute md:hidden right-4 top-4 rounded-sm opacity-70 transition-opacity hover:opacity-100" type="button">
<svg class="h-4 w-4" fill="currentColor" height="24" stroke="none" viewbox="0 96 960 960" width="24" xmlns="http://www.w3.org/2000/svg">
<path d="M480 632 284 828q-11 11-28 11t-28-11q-11-11-11-28t11-28l196-196-196-196q-11-11-11-28t11-28q11-11 28-11t28 11l196 196 196-196q11-11 28-11t28 11q11 11 11 28t-11 28L536 576l196 196q11 11 11 28t-11 28q-11 11-28 11t-28-11L480 632Z"></path>
</svg>
</button>
</aside>
<main class="relative py-6 lg:gap-10 lg:py-8 xl:grid xl:grid-cols-[1fr_300px]">
<div class="w-full min-w-0 mx-auto">
<nav aria-label="breadcrumbs" class="flex items-center mb-4 space-x-1 text-sm text-muted-foreground">
<a class="overflow-hidden text-ellipsis whitespace-nowrap hover:text-foreground" href="../index.html">
<span class="hidden md:inline">torch<span style="border-radius: 4px; color: white; text-justify: none; padding: 0px 2px 0px 2px; background: linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3)); -moz-linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3)); -webkit-linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3));">-ttt</span></span>
<svg aria-label="Home" class="md:hidden" fill="currentColor" height="18" stroke="none" viewbox="0 96 960 960" width="18" xmlns="http://www.w3.org/2000/svg">
<path d="M240 856h120V616h240v240h120V496L480 316 240 496v360Zm-80 80V456l320-240 320 240v480H520V696h-80v240H160Zm320-350Z"></path>
</svg>
</a>
<div class="mr-1">/</div><a class="hover:text-foreground overflow-hidden text-ellipsis whitespace-nowrap" href="index.html">Tutorials</a>
<div class="mr-1">/</div><span aria-current="page" class="font-medium text-foreground overflow-hidden text-ellipsis whitespace-nowrap">Test-Time Training for Corrupted WILDS Dataset</span>
</nav>
<div id="content" role="main">
<div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-auto-examples-03-mae-bert-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="test-time-training-for-corrupted-wilds-dataset">
<span id="sphx-glr-auto-examples-03-mae-bert-py"></span><h1>Test-Time Training for Corrupted WILDS Dataset<a @click.prevent="window.navigator.clipboard.writeText($el.href); $el.setAttribute('data-tooltip', 'Copied!'); setTimeout(() =&gt; $el.setAttribute('data-tooltip', 'Copy link to this element'), 2000)" aria-label="Copy link to this element" class="headerlink" data-tooltip="Copy link to this element" href="#test-time-training-for-corrupted-wilds-dataset"><span>#</span></a></h1>
<p>Explore how Test-Time Training (TTT) can improve model performance under data corruption,
using the BERT model fine-tuned with a MaskedTTT engine on the Amazon Reviews dataset.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="nb">print</span><span class="p">(</span><span class="s2">"Uncomment the line below to install torch-ttt if you're running this in Colab"</span><span class="p">)</span>
</span><span id="line-2"><span class="c1"># !pip install git+https://github.com/nikitadurasov/torch-ttt.git</span>
</span></code></pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span><code><span id="line-1">Uncomment the line below to install torch-ttt if you're running this in Colab
</span></code></pre></div>
</div>
<section id="helper-functions">
<h2>Helper Functions<a @click.prevent="window.navigator.clipboard.writeText($el.href); $el.setAttribute('data-tooltip', 'Copied!'); setTimeout(() =&gt; $el.setAttribute('data-tooltip', 'Copy link to this element'), 2000)" aria-label="Copy link to this element" class="headerlink" data-tooltip="Copy link to this element" href="#helper-functions" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#helper-functions'"><span>#</span></a></h2>
<section id="data-preparation">
<h3>Data Preparation<a @click.prevent="window.navigator.clipboard.writeText($el.href); $el.setAttribute('data-tooltip', 'Copied!'); setTimeout(() =&gt; $el.setAttribute('data-tooltip', 'Copy link to this element'), 2000)" aria-label="Copy link to this element" class="headerlink" data-tooltip="Copy link to this element" href="#data-preparation" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#data-preparation'"><span>#</span></a></h3>
<p>We will work with the Amazon Reviews dataset, which contains customer reviews for a wide range of products.
To simulate distribution shift, we will use both a clean version of the dataset and a corrupted version that includes noise in the form of typos and text perturbations.
For this tutorial, we’ll focus on a single corruption type: character-level typos.</p>
<p>Let’s start by downloading both the clean and corrupted versions of the Amazon Reviews dataset.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
</span><span id="line-2">
</span><span id="line-3"><span class="c1"># Download Amazon Review "electronics" category training set</span>
</span><span id="line-4"><span class="n">os</span><span class="o">.</span><span class="n">system</span><span class="p">(</span><span class="s2">"gdown 1mpswNa37wFhcGd-U07nMUFeF0_X4AEMi"</span><span class="p">)</span>
</span><span id="line-5">
</span><span id="line-6"><span class="c1"># Download Amazon Review "electronics" category validation set</span>
</span><span id="line-7"><span class="n">os</span><span class="o">.</span><span class="n">system</span><span class="p">(</span><span class="s2">"gdown 1UbhmtFn7GEMmcoKdb2lbpf54yZV9mLoF"</span><span class="p">)</span>
</span></code></pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span><code><span id="line-1">0
</span></code></pre></div>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
</span><span id="line-2"><span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">Dataset</span>
</span><span id="line-3"><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">accuracy_score</span>
</span><span id="line-4"><span class="kn">from</span><span class="w"> </span><span class="nn">transformers.modeling_outputs</span><span class="w"> </span><span class="kn">import</span> <span class="n">SequenceClassifierOutput</span>
</span><span id="line-5"><span class="kn">from</span><span class="w"> </span><span class="nn">tqdm</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>
</span><span id="line-6"><span class="kn">from</span><span class="w"> </span><span class="nn">copy</span><span class="w"> </span><span class="kn">import</span> <span class="n">deepcopy</span>
</span></code></pre></div>
</div>
</section>
</section>
<section id="loading-wilds-dataset">
<h2>Loading WILDS dataset<a @click.prevent="window.navigator.clipboard.writeText($el.href); $el.setAttribute('data-tooltip', 'Copied!'); setTimeout(() =&gt; $el.setAttribute('data-tooltip', 'Copy link to this element'), 2000)" aria-label="Copy link to this element" class="headerlink" data-tooltip="Copy link to this element" href="#loading-wilds-dataset" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#loading-wilds-dataset'"><span>#</span></a></h2>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="line-2"><span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
</span><span id="line-3"><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">BertTokenizer</span><span class="p">,</span> <span class="n">BertForSequenceClassification</span>
</span><span id="line-4"><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_scheduler</span>
</span><span id="line-5"><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">accuracy_score</span>
</span><span id="line-6"><span class="kn">from</span><span class="w"> </span><span class="nn">tqdm</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>
</span><span id="line-7"><span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">Subset</span>
</span><span id="line-8">
</span><span id="line-9"><span class="c1"># Set device</span>
</span><span id="line-10"><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">'cuda'</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">'cpu'</span><span class="p">)</span>
</span><span id="line-11">
</span><span id="line-12"><span class="k">class</span><span class="w"> </span><span class="nc">AmazonReviewDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
</span><span id="line-13">    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
</span><span id="line-14">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="line-15">        <span class="c1"># Load the list of (text, label, input_ids)</span>
</span><span id="line-16">        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>  <span class="c1"># or use json.load(...) if it's a JSON file</span>
</span><span id="line-17">
</span><span id="line-18">    <span class="k">def</span><span class="w"> </span><span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="line-19">        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
</span><span id="line-20">
</span><span id="line-21">    <span class="k">def</span><span class="w"> </span><span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
</span><span id="line-22">        <span class="n">text</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">input_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
</span><span id="line-23">        <span class="n">label</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
</span><span id="line-24">        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
</span><span id="line-25">        <span class="k">return</span> <span class="n">text</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">input_ids</span>
</span><span id="line-26">
</span><span id="line-27"><span class="n">train_data</span> <span class="o">=</span> <span class="n">AmazonReviewDataset</span><span class="p">(</span><span class="s2">"train_amazon_review_electronics.pt"</span><span class="p">)</span>
</span><span id="line-28"><span class="n">val_data</span> <span class="o">=</span> <span class="n">AmazonReviewDataset</span><span class="p">(</span><span class="s2">"test_amazon_review_electronics.pt"</span><span class="p">)</span>
</span></code></pre></div>
</div>
</section>
<section id="loading-pretrained-bert">
<h2>Loading Pretrained BERT<a @click.prevent="window.navigator.clipboard.writeText($el.href); $el.setAttribute('data-tooltip', 'Copied!'); setTimeout(() =&gt; $el.setAttribute('data-tooltip', 'Copy link to this element'), 2000)" aria-label="Copy link to this element" class="headerlink" data-tooltip="Copy link to this element" href="#loading-pretrained-bert" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#loading-pretrained-bert'"><span>#</span></a></h2>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="line-2"><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">BertTokenizer</span><span class="p">,</span> <span class="n">BertModel</span><span class="p">,</span> <span class="n">BertConfig</span>
</span><span id="line-3"><span class="kn">from</span><span class="w"> </span><span class="nn">transformers.models.bert.modeling_bert</span><span class="w"> </span><span class="kn">import</span> <span class="n">BertLMPredictionHead</span><span class="p">,</span> <span class="n">BertForMaskedLM</span>
</span><span id="line-4">
</span><span id="line-5"><span class="c1"># Load tokenizer, config, and base BERT (no head)</span>
</span><span id="line-6"><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">BertTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">"bert-base-uncased"</span><span class="p">)</span> <span class="c1">#bert-base-uncased</span>
</span><span id="line-7"><span class="n">config</span> <span class="o">=</span> <span class="n">BertConfig</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">"bert-base-uncased"</span><span class="p">)</span>
</span><span id="line-8">
</span><span id="line-9"><span class="c1"># Load a full BERT with pretrained MLM head</span>
</span><span id="line-10"><span class="n">mlm_model</span> <span class="o">=</span> <span class="n">BertForMaskedLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">"bert-base-uncased"</span><span class="p">)</span>
</span><span id="line-11">
</span><span id="line-12"><span class="c1"># Extract encoder and MLM head from it</span>
</span><span id="line-13"><span class="n">bert</span> <span class="o">=</span> <span class="n">mlm_model</span><span class="o">.</span><span class="n">bert</span>
</span><span id="line-14"><span class="n">mlm_head</span> <span class="o">=</span> <span class="n">mlm_model</span><span class="o">.</span><span class="n">cls</span>
</span><span id="line-15">
</span><span id="line-16"><span class="c1"># Input sentence with a masked token</span>
</span><span id="line-17"><span class="n">text</span> <span class="o">=</span> <span class="s2">"The Milky Way is a spiral [MASK]."</span>
</span><span id="line-18"><span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>
</span><span id="line-19"><span class="n">input_ids</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span>
</span><span id="line-20">
</span><span id="line-21"><span class="c1"># Get index of [MASK] token</span>
</span><span id="line-22"><span class="n">mask_token_index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">input_ids</span> <span class="o">==</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">mask_token_id</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
</span><span id="line-23">
</span><span id="line-24"><span class="c1"># Forward pass through BERT to get hidden states</span>
</span><span id="line-25"><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span><span id="line-26">    <span class="n">outputs</span> <span class="o">=</span> <span class="n">bert</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="line-27">    <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">last_hidden_state</span>  <span class="c1"># (batch_size, seq_len, hidden_dim)</span>
</span><span id="line-28">
</span><span id="line-29"><span class="c1"># Apply MLM head to get logits over vocabulary</span>
</span><span id="line-30"><span class="n">logits</span> <span class="o">=</span> <span class="n">mlm_head</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>  <span class="c1"># (batch_size, seq_len, vocab_size)</span>
</span><span id="line-31">
</span><span id="line-32"><span class="c1"># Get logits at [MASK] position</span>
</span><span id="line-33"><span class="n">mask_logits</span> <span class="o">=</span> <span class="n">logits</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">mask_token_index</span><span class="p">,</span> <span class="p">:]</span>  <span class="c1"># shape: (1, vocab_size)</span>
</span><span id="line-34">
</span><span id="line-35"><span class="c1"># Get top-3 predicted tokens</span>
</span><span id="line-36"><span class="n">top_3_tokens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">mask_logits</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">indices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
</span><span id="line-37">
</span><span id="line-38"><span class="c1"># Print predictions</span>
</span><span id="line-39"><span class="nb">print</span><span class="p">(</span><span class="s2">"Original:"</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
</span><span id="line-40"><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">token_id</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">top_3_tokens</span><span class="p">):</span>
</span><span id="line-41">    <span class="n">predicted_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">([</span><span class="n">token_id</span><span class="p">])</span>
</span><span id="line-42">    <span class="n">filled_text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">mask_token</span><span class="p">,</span> <span class="n">predicted_token</span><span class="p">)</span>
</span><span id="line-43">    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">. </span><span class="si">{</span><span class="n">filled_text</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</span></code></pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span><code><span id="line-1">Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`
</span><span id="line-2">Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']
</span><span id="line-3">- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
</span><span id="line-4">- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
</span><span id="line-5">Original: The Milky Way is a spiral [MASK].
</span><span id="line-6">1. The Milky Way is a spiral galaxy.
</span><span id="line-7">2. The Milky Way is a spiral galaxies.
</span><span id="line-8">3. The Milky Way is a spiral system.
</span><span id="line-9">4. The Milky Way is a spiral nebula.
</span><span id="line-10">5. The Milky Way is a spiral constellation.
</span></code></pre></div>
</div>
</section>
<section id="finetuning-bert">
<h2>Finetuning BERT<a @click.prevent="window.navigator.clipboard.writeText($el.href); $el.setAttribute('data-tooltip', 'Copied!'); setTimeout(() =&gt; $el.setAttribute('data-tooltip', 'Copy link to this element'), 2000)" aria-label="Copy link to this element" class="headerlink" data-tooltip="Copy link to this element" href="#finetuning-bert" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#finetuning-bert'"><span>#</span></a></h2>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="line-2"><span class="kn">import</span><span class="w"> </span><span class="nn">random</span>
</span><span id="line-3"><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
</span><span id="line-4">
</span><span id="line-5"><span class="n">seed</span> <span class="o">=</span> <span class="mi">42</span>
</span><span id="line-6"><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
</span><span id="line-7"><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
</span><span id="line-8"><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
</span><span id="line-9"><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
</span><span id="line-10">
</span><span id="line-11"><span class="n">device</span> <span class="o">=</span> <span class="s2">"cuda"</span>
</span></code></pre></div>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="kn">from</span><span class="w"> </span><span class="nn">collections</span><span class="w"> </span><span class="kn">import</span> <span class="n">Counter</span>
</span><span id="line-2"><span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">train_data</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">))]</span>
</span><span id="line-3"><span class="n">sorted_freq</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">Counter</span><span class="p">([</span><span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">labels</span><span class="p">])</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</span><span id="line-4"><span class="nb">print</span><span class="p">(</span><span class="n">sorted_freq</span><span class="p">)</span>
</span></code></pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span><code><span id="line-1">[(0, 76), (1, 69), (2, 215), (3, 632), (4, 1744)]
</span></code></pre></div>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">WeightedRandomSampler</span>
</span><span id="line-2">
</span><span id="line-3"><span class="c1"># Count samples per class</span>
</span><span id="line-4"><span class="n">class_counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
</span><span id="line-5"><span class="n">class_weights</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">/</span> <span class="n">class_counts</span>
</span><span id="line-6"><span class="n">sample_weights</span> <span class="o">=</span> <span class="n">class_weights</span><span class="p">[</span><span class="n">labels</span><span class="p">]</span>
</span><span id="line-7">
</span><span id="line-8"><span class="n">sampler</span> <span class="o">=</span> <span class="n">WeightedRandomSampler</span><span class="p">(</span>
</span><span id="line-9">    <span class="n">weights</span><span class="o">=</span><span class="n">sample_weights</span><span class="p">,</span>
</span><span id="line-10">    <span class="n">num_samples</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">sample_weights</span><span class="p">),</span>
</span><span id="line-11">    <span class="n">replacement</span><span class="o">=</span><span class="kc">True</span>
</span><span id="line-12"><span class="p">)</span>
</span></code></pre></div>
</div>
<p>Class sample counts</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="n">counts</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">sorted_freq</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
</span><span id="line-2">
</span><span id="line-3"><span class="c1"># Inverse frequency</span>
</span><span id="line-4"><span class="n">inv_freq</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">counts</span>
</span><span id="line-5">
</span><span id="line-6"><span class="c1"># Normalize (optional but recommended)</span>
</span><span id="line-7"><span class="n">weights</span> <span class="o">=</span> <span class="n">inv_freq</span> <span class="o">/</span> <span class="n">inv_freq</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</span><span id="line-8">
</span><span id="line-9"><span class="c1"># Classification head (on top of BERT)</span>
</span><span id="line-10"><span class="k">class</span><span class="w"> </span><span class="nc">BertForClassification</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="line-11">    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">bert</span><span class="p">,</span> <span class="n">mlm_head</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
</span><span id="line-12">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="line-13">        <span class="bp">self</span><span class="o">.</span><span class="n">bert</span> <span class="o">=</span> <span class="n">bert</span>  <span class="c1"># the encoder you already have</span>
</span><span id="line-14">        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
</span><span id="line-15">        <span class="bp">self</span><span class="o">.</span><span class="n">mlm_head</span> <span class="o">=</span> <span class="n">mlm_head</span>
</span><span id="line-16">        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
</span><span id="line-17">            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">bert</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span>
</span><span id="line-18">            <span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">(),</span>
</span><span id="line-19">            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span>
</span><span id="line-20">            <span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">(),</span>
</span><span id="line-21">            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
</span><span id="line-22">        <span class="p">)</span>
</span><span id="line-23">
</span><span id="line-24">    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="line-25">        <span class="n">labels</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"labels"</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</span><span id="line-26">
</span><span id="line-27">        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bert</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="line-28">
</span><span id="line-29">        <span class="c1"># Take [CLS] token</span>
</span><span id="line-30">        <span class="n">cls_token</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">last_hidden_state</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
</span><span id="line-31">        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">cls_token</span><span class="p">)</span>
</span><span id="line-32">        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="line-33">
</span><span id="line-34">        <span class="n">mlm_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlm_head</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">last_hidden_state</span><span class="p">)</span>
</span><span id="line-35">
</span><span id="line-36">        <span class="c1"># Optional loss</span>
</span><span id="line-37">        <span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="line-38">        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="line-39">            <span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">weight</span><span class="o">=</span><span class="n">weights</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">device</span><span class="p">))(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</span><span id="line-40">
</span><span id="line-41">        <span class="k">return</span> <span class="n">SequenceClassifierOutput</span><span class="p">(</span>
</span><span id="line-42">            <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
</span><span id="line-43">            <span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">,</span>
</span><span id="line-44">            <span class="n">hidden_states</span><span class="o">=</span><span class="n">outputs</span><span class="o">.</span><span class="n">hidden_states</span><span class="p">,</span>
</span><span id="line-45">            <span class="n">attentions</span><span class="o">=</span><span class="n">outputs</span><span class="o">.</span><span class="n">attentions</span><span class="p">,</span>
</span><span id="line-46">        <span class="p">)</span>
</span><span id="line-47">
</span><span id="line-48"><span class="c1"># Initialize classifier model</span>
</span><span id="line-49"><span class="n">classifier</span> <span class="o">=</span> <span class="n">BertForClassification</span><span class="p">(</span><span class="n">bert</span><span class="p">,</span> <span class="n">mlm_head</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span><span id="line-50"><span class="n">classifier</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</span></code></pre></div>
</div>
<p>Use HuggingFace tokenizer</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">BertTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">"bert-base-uncased"</span><span class="p">)</span>
</span><span id="line-2">
</span><span id="line-3"><span class="k">def</span><span class="w"> </span><span class="nf">tokenize_batch</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
</span><span id="line-4">    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s1">'text'</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>
</span><span id="line-5">
</span><span id="line-6"><span class="c1"># Custom collate function for DataLoader</span>
</span><span id="line-7"><span class="k">def</span><span class="w"> </span><span class="nf">collate_fn</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
</span><span id="line-8">    <span class="c1"># print(batch[0])</span>
</span><span id="line-9">    <span class="n">texts</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">]</span>
</span><span id="line-10">    <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">])</span>
</span><span id="line-11">    <span class="n">tokenized</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">texts</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>
</span><span id="line-12">    <span class="k">return</span> <span class="p">{</span><span class="o">**</span><span class="n">tokenized</span><span class="p">,</span> <span class="s1">'labels'</span><span class="p">:</span> <span class="n">labels</span><span class="p">}</span>
</span><span id="line-13">
</span><span id="line-14"><span class="n">num_workers</span> <span class="o">=</span> <span class="mi">32</span>
</span><span id="line-15"><span class="n">epochs_num</span> <span class="o">=</span> <span class="mi">20</span>
</span><span id="line-16"><span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">)</span>
</span><span id="line-17"><span class="n">val_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">val_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span><span class="p">)</span>
</span><span id="line-18">
</span><span id="line-19"><span class="c1"># Optimizer</span>
</span><span id="line-20"><span class="n">classifier</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span><span id="line-21"><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">classifier</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>
</span><span id="line-22"><span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">get_scheduler</span><span class="p">(</span><span class="s2">"linear"</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">num_warmup_steps</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
</span><span id="line-23">                             <span class="n">num_training_steps</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span><span class="o">*</span><span class="n">epochs_num</span><span class="p">)</span>
</span></code></pre></div>
</div>
<p>Training loop</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs_num</span><span class="p">):</span>
</span><span id="line-2">    <span class="n">classifier</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</span><span id="line-3">    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
</span><span id="line-4">        <span class="n">batch</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
</span><span id="line-5">        <span class="n">outputs</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">(</span><span class="o">**</span><span class="n">batch</span><span class="p">)</span>
</span><span id="line-6">        <span class="n">loss</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">loss</span>
</span><span id="line-7">        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</span><span id="line-8">        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span><span id="line-9">        <span class="n">lr_scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span><span id="line-10">        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
</span><span id="line-11">
</span><span id="line-12">    <span class="c1"># Validation</span>
</span><span id="line-13">    <span class="n">classifier</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</span><span id="line-14">    <span class="n">all_preds</span><span class="p">,</span> <span class="n">all_labels</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
</span><span id="line-15">    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span><span id="line-16">        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">val_loader</span><span class="p">):</span>
</span><span id="line-17">            <span class="n">batch</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
</span><span id="line-18">            <span class="n">outputs</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">(</span><span class="o">**</span><span class="n">batch</span><span class="p">)</span>
</span><span id="line-19">            <span class="n">preds</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">logits</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span><span id="line-20">            <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s1">'labels'</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span><span id="line-21">            <span class="n">all_preds</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span>
</span><span id="line-22">            <span class="n">all_labels</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
</span><span id="line-23">
</span><span id="line-24">    <span class="n">acc</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">all_labels</span><span class="p">,</span> <span class="n">all_preds</span><span class="p">)</span>
</span><span id="line-25">    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Validation Accuracy after epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">acc</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</span></code></pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span><code><span id="line-1">Validation Accuracy after epoch 1: 0.0739
</span><span id="line-2">Validation Accuracy after epoch 2: 0.0897
</span><span id="line-3">Validation Accuracy after epoch 3: 0.0940
</span><span id="line-4">Validation Accuracy after epoch 4: 0.2106
</span><span id="line-5">Validation Accuracy after epoch 5: 0.1844
</span><span id="line-6">Validation Accuracy after epoch 6: 0.1972
</span><span id="line-7">Validation Accuracy after epoch 7: 0.2186
</span><span id="line-8">Validation Accuracy after epoch 8: 0.2485
</span><span id="line-9">Validation Accuracy after epoch 9: 0.3779
</span><span id="line-10">Validation Accuracy after epoch 10: 0.4890
</span><span id="line-11">Validation Accuracy after epoch 11: 0.4243
</span><span id="line-12">Validation Accuracy after epoch 12: 0.4860
</span><span id="line-13">Validation Accuracy after epoch 13: 0.5317
</span><span id="line-14">Validation Accuracy after epoch 14: 0.5830
</span><span id="line-15">Validation Accuracy after epoch 15: 0.5714
</span><span id="line-16">Validation Accuracy after epoch 16: 0.5952
</span><span id="line-17">Validation Accuracy after epoch 17: 0.5781
</span><span id="line-18">Validation Accuracy after epoch 18: 0.5983
</span><span id="line-19">Validation Accuracy after epoch 19: 0.5617
</span><span id="line-20">Validation Accuracy after epoch 20: 0.6081
</span></code></pre></div>
</div>
<p>Validation</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="n">classifier</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</span><span id="line-2"><span class="n">all_preds</span><span class="p">,</span> <span class="n">all_labels</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
</span><span id="line-3"><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span><span id="line-4">    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tqdm</span><span class="p">(</span><span class="n">val_loader</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">val_loader</span><span class="p">))):</span>
</span><span id="line-5">        <span class="n">batch</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
</span><span id="line-6">        <span class="n">outputs</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">(</span><span class="o">**</span><span class="n">batch</span><span class="p">)</span>
</span><span id="line-7">        <span class="n">preds</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">logits</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span><span id="line-8">        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s1">'labels'</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span><span id="line-9">        <span class="n">all_preds</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span>
</span><span id="line-10">        <span class="n">all_labels</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
</span><span id="line-11">
</span><span id="line-12"><span class="n">acc</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">all_labels</span><span class="p">,</span> <span class="n">all_preds</span><span class="p">)</span>
</span><span id="line-13"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Validation Accuracy after epoch: </span><span class="si">{</span><span class="n">acc</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</span></code></pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span><code><span id="line-1">  0%|          | 0/52 [00:00&lt;?, ?it/s]
</span><span id="line-2">  2%|▏         | 1/52 [00:01&lt;01:12,  1.42s/it]
</span><span id="line-3">  4%|▍         | 2/52 [00:01&lt;00:32,  1.54it/s]
</span><span id="line-4">  8%|▊         | 4/52 [00:01&lt;00:13,  3.51it/s]
</span><span id="line-5"> 12%|█▏        | 6/52 [00:01&lt;00:08,  5.64it/s]
</span><span id="line-6"> 15%|█▌        | 8/52 [00:01&lt;00:05,  7.75it/s]
</span><span id="line-7"> 19%|█▉        | 10/52 [00:02&lt;00:04,  9.70it/s]
</span><span id="line-8"> 23%|██▎       | 12/52 [00:02&lt;00:03, 11.40it/s]
</span><span id="line-9"> 27%|██▋       | 14/52 [00:02&lt;00:02, 12.78it/s]
</span><span id="line-10"> 31%|███       | 16/52 [00:02&lt;00:02, 13.84it/s]
</span><span id="line-11"> 35%|███▍      | 18/52 [00:02&lt;00:02, 14.76it/s]
</span><span id="line-12"> 38%|███▊      | 20/52 [00:02&lt;00:02, 14.92it/s]
</span><span id="line-13"> 42%|████▏     | 22/52 [00:02&lt;00:01, 15.57it/s]
</span><span id="line-14"> 46%|████▌     | 24/52 [00:02&lt;00:01, 16.11it/s]
</span><span id="line-15"> 50%|█████     | 26/52 [00:02&lt;00:01, 16.50it/s]
</span><span id="line-16"> 54%|█████▍    | 28/52 [00:03&lt;00:01, 16.79it/s]
</span><span id="line-17"> 58%|█████▊    | 30/52 [00:03&lt;00:01, 16.88it/s]
</span><span id="line-18"> 62%|██████▏   | 32/52 [00:03&lt;00:01, 16.98it/s]
</span><span id="line-19"> 65%|██████▌   | 34/52 [00:03&lt;00:01, 17.05it/s]
</span><span id="line-20"> 69%|██████▉   | 36/52 [00:03&lt;00:00, 17.12it/s]
</span><span id="line-21"> 73%|███████▎  | 38/52 [00:03&lt;00:00, 17.20it/s]
</span><span id="line-22"> 77%|███████▋  | 40/52 [00:03&lt;00:00, 17.19it/s]
</span><span id="line-23"> 81%|████████  | 42/52 [00:03&lt;00:00, 17.22it/s]
</span><span id="line-24"> 85%|████████▍ | 44/52 [00:03&lt;00:00, 17.29it/s]
</span><span id="line-25"> 88%|████████▊ | 46/52 [00:04&lt;00:00, 17.27it/s]
</span><span id="line-26"> 92%|█████████▏| 48/52 [00:04&lt;00:00, 17.29it/s]
</span><span id="line-27"> 96%|█████████▌| 50/52 [00:04&lt;00:00, 17.33it/s]
</span><span id="line-28">100%|██████████| 52/52 [00:04&lt;00:00, 11.49it/s]
</span><span id="line-29">Validation Accuracy after epoch: 0.6081
</span></code></pre></div>
</div>
</section>
<section id="evalating-bert-on-corrupted-data">
<h2>Evalating BERT on Corrupted Data<a @click.prevent="window.navigator.clipboard.writeText($el.href); $el.setAttribute('data-tooltip', 'Copied!'); setTimeout(() =&gt; $el.setAttribute('data-tooltip', 'Copy link to this element'), 2000)" aria-label="Copy link to this element" class="headerlink" data-tooltip="Copy link to this element" href="#evalating-bert-on-corrupted-data" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#evalating-bert-on-corrupted-data'"><span>#</span></a></h2>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="kn">import</span><span class="w"> </span><span class="nn">random</span>
</span><span id="line-2">
</span><span id="line-3"><span class="k">def</span><span class="w"> </span><span class="nf">corrupt_characters</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">prob</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
</span><span id="line-4">    <span class="n">corrupted</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="line-5">    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">():</span>
</span><span id="line-6">        <span class="n">chars</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
</span><span id="line-7">        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">chars</span><span class="p">)):</span>
</span><span id="line-8">            <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">prob</span><span class="p">:</span>
</span><span id="line-9">                <span class="n">op</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="s1">'swap'</span><span class="p">,</span> <span class="s1">'drop'</span><span class="p">,</span> <span class="s1">'repeat'</span><span class="p">])</span>
</span><span id="line-10">                <span class="k">if</span> <span class="n">op</span> <span class="o">==</span> <span class="s1">'swap'</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">chars</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="line-11">                    <span class="n">chars</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">chars</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">chars</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">chars</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</span><span id="line-12">                <span class="k">elif</span> <span class="n">op</span> <span class="o">==</span> <span class="s1">'drop'</span><span class="p">:</span>
</span><span id="line-13">                    <span class="n">chars</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="s1">''</span>
</span><span id="line-14">                <span class="k">elif</span> <span class="n">op</span> <span class="o">==</span> <span class="s1">'repeat'</span><span class="p">:</span>
</span><span id="line-15">                    <span class="n">chars</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">chars</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span>
</span><span id="line-16">        <span class="n">corrupted</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">chars</span><span class="p">))</span>
</span><span id="line-17">    <span class="k">return</span> <span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">corrupted</span><span class="p">)</span>
</span><span id="line-18">
</span><span id="line-19"><span class="k">def</span><span class="w"> </span><span class="nf">corrupt_words</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">prob</span><span class="o">=</span><span class="mf">0.2</span><span class="p">):</span>
</span><span id="line-20">    <span class="n">words</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
</span><span id="line-21">    <span class="n">new_words</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="line-22">
</span><span id="line-23">    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">:</span>
</span><span id="line-24">        <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">prob</span><span class="p">:</span>
</span><span id="line-25">            <span class="n">op</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="s1">'delete'</span><span class="p">,</span> <span class="s1">'shuffle'</span><span class="p">])</span>
</span><span id="line-26">            <span class="k">if</span> <span class="n">op</span> <span class="o">==</span> <span class="s1">'delete'</span><span class="p">:</span>
</span><span id="line-27">                <span class="k">continue</span>
</span><span id="line-28">            <span class="k">elif</span> <span class="n">op</span> <span class="o">==</span> <span class="s1">'shuffle'</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">3</span><span class="p">:</span>
</span><span id="line-29">                <span class="n">middle</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">word</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</span><span id="line-30">                <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">middle</span><span class="p">)</span>
</span><span id="line-31">                <span class="n">word</span> <span class="o">=</span> <span class="n">word</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">middle</span><span class="p">)</span> <span class="o">+</span> <span class="n">word</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="line-32">        <span class="n">new_words</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
</span><span id="line-33">    <span class="k">return</span> <span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">new_words</span><span class="p">)</span>
</span><span id="line-34">
</span><span id="line-35"><span class="k">def</span><span class="w"> </span><span class="nf">corrupt_text</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">char_prob</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">word_prob</span><span class="o">=</span><span class="mf">0.2</span><span class="p">):</span>
</span><span id="line-36">    <span class="k">return</span> <span class="n">corrupt_characters</span><span class="p">(</span><span class="n">corrupt_words</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">word_prob</span><span class="p">),</span> <span class="n">char_prob</span><span class="p">)</span>
</span><span id="line-37">
</span><span id="line-38"><span class="k">class</span><span class="w"> </span><span class="nc">CorruptedDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
</span><span id="line-39">
</span><span id="line-40">    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">char_prob</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">word_prob</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
</span><span id="line-41">        <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span>
</span><span id="line-42">        <span class="bp">self</span><span class="o">.</span><span class="n">char_prob</span> <span class="o">=</span> <span class="n">char_prob</span>
</span><span id="line-43">        <span class="bp">self</span><span class="o">.</span><span class="n">word_prob</span> <span class="o">=</span> <span class="n">word_prob</span>
</span><span id="line-44">
</span><span id="line-45">    <span class="k">def</span><span class="w"> </span><span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
</span><span id="line-46">        <span class="n">sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
</span><span id="line-47">        <span class="n">text</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="line-48">        <span class="n">corrupted_text</span> <span class="o">=</span> <span class="n">corrupt_text</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">char_prob</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">word_prob</span><span class="p">)</span>
</span><span id="line-49">        <span class="k">return</span> <span class="p">(</span><span class="n">corrupted_text</span><span class="p">,</span> <span class="n">sample</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">sample</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
</span><span id="line-50">
</span><span id="line-51">    <span class="k">def</span><span class="w"> </span><span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="line-52">        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
</span><span id="line-53">
</span><span id="line-54"><span class="n">text</span> <span class="o">=</span> <span class="s2">"This is an example of a corrupted sentence using Python"</span>
</span><span id="line-55"><span class="nb">print</span><span class="p">(</span><span class="n">corrupt_text</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">))</span>
</span></code></pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span><code><span id="line-1">Tihs is an example of a crrupted setnence Python
</span></code></pre></div>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="n">corrupted_val_data</span> <span class="o">=</span> <span class="n">CorruptedDataset</span><span class="p">(</span><span class="n">val_data</span><span class="p">,</span> <span class="n">char_prob</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">word_prob</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</span><span id="line-2"><span class="n">corrupted_val_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">corrupted_val_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span><span class="p">)</span>
</span></code></pre></div>
</div>
<p>Corrupted Validation</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="n">classifier</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</span><span id="line-2"><span class="n">all_preds</span><span class="p">,</span> <span class="n">all_labels</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
</span><span id="line-3"><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span><span id="line-4">    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tqdm</span><span class="p">(</span><span class="n">corrupted_val_loader</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">corrupted_val_loader</span><span class="p">))):</span>
</span><span id="line-5">        <span class="n">batch</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
</span><span id="line-6">        <span class="n">outputs</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">(</span><span class="o">**</span><span class="n">batch</span><span class="p">)</span>
</span><span id="line-7">        <span class="n">preds</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">logits</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span><span id="line-8">        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s1">'labels'</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span><span id="line-9">        <span class="n">all_preds</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span>
</span><span id="line-10">        <span class="n">all_labels</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
</span><span id="line-11">
</span><span id="line-12"><span class="n">acc</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">all_labels</span><span class="p">,</span> <span class="n">all_preds</span><span class="p">)</span>
</span><span id="line-13"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Validation Accuracy after epoch: </span><span class="si">{</span><span class="n">acc</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</span></code></pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span><code><span id="line-1">  0%|          | 0/52 [00:00&lt;?, ?it/s]
</span><span id="line-2">  2%|▏         | 1/52 [00:01&lt;01:26,  1.70s/it]
</span><span id="line-3">  6%|▌         | 3/52 [00:01&lt;00:24,  2.01it/s]
</span><span id="line-4"> 10%|▉         | 5/52 [00:01&lt;00:12,  3.69it/s]
</span><span id="line-5"> 13%|█▎        | 7/52 [00:02&lt;00:08,  5.54it/s]
</span><span id="line-6"> 17%|█▋        | 9/52 [00:02&lt;00:05,  7.46it/s]
</span><span id="line-7"> 21%|██        | 11/52 [00:02&lt;00:04,  9.32it/s]
</span><span id="line-8"> 25%|██▌       | 13/52 [00:02&lt;00:03, 11.02it/s]
</span><span id="line-9"> 29%|██▉       | 15/52 [00:02&lt;00:02, 12.48it/s]
</span><span id="line-10"> 33%|███▎      | 17/52 [00:02&lt;00:02, 13.72it/s]
</span><span id="line-11"> 37%|███▋      | 19/52 [00:02&lt;00:02, 14.53it/s]
</span><span id="line-12"> 40%|████      | 21/52 [00:02&lt;00:02, 15.32it/s]
</span><span id="line-13"> 44%|████▍     | 23/52 [00:03&lt;00:01, 15.87it/s]
</span><span id="line-14"> 48%|████▊     | 25/52 [00:03&lt;00:01, 16.33it/s]
</span><span id="line-15"> 52%|█████▏    | 27/52 [00:03&lt;00:01, 16.68it/s]
</span><span id="line-16"> 56%|█████▌    | 29/52 [00:03&lt;00:01, 16.93it/s]
</span><span id="line-17"> 60%|█████▉    | 31/52 [00:03&lt;00:01, 17.08it/s]
</span><span id="line-18"> 63%|██████▎   | 33/52 [00:03&lt;00:01, 17.21it/s]
</span><span id="line-19"> 67%|██████▋   | 35/52 [00:03&lt;00:00, 17.31it/s]
</span><span id="line-20"> 71%|███████   | 37/52 [00:03&lt;00:00, 17.37it/s]
</span><span id="line-21"> 75%|███████▌  | 39/52 [00:03&lt;00:00, 17.34it/s]
</span><span id="line-22"> 79%|███████▉  | 41/52 [00:04&lt;00:00, 17.39it/s]
</span><span id="line-23"> 83%|████████▎ | 43/52 [00:04&lt;00:00, 17.27it/s]
</span><span id="line-24"> 87%|████████▋ | 45/52 [00:04&lt;00:00, 17.34it/s]
</span><span id="line-25"> 90%|█████████ | 47/52 [00:04&lt;00:00, 17.39it/s]
</span><span id="line-26"> 94%|█████████▍| 49/52 [00:04&lt;00:00, 17.44it/s]
</span><span id="line-27"> 98%|█████████▊| 51/52 [00:04&lt;00:00, 17.38it/s]
</span><span id="line-28">100%|██████████| 52/52 [00:04&lt;00:00, 10.98it/s]
</span><span id="line-29">Validation Accuracy after epoch: 0.3791
</span></code></pre></div>
</div>
</section>
<section id="masked-test-time-training-for-generalization">
<h2>Masked Test-Time Training for Generalization<a @click.prevent="window.navigator.clipboard.writeText($el.href); $el.setAttribute('data-tooltip', 'Copied!'); setTimeout(() =&gt; $el.setAttribute('data-tooltip', 'Copy link to this element'), 2000)" aria-label="Copy link to this element" class="headerlink" data-tooltip="Copy link to this element" href="#masked-test-time-training-for-generalization" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#masked-test-time-training-for-generalization'"><span>#</span></a></h2>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="kn">from</span><span class="w"> </span><span class="nn">torch_ttt.engine.masked_ttt_engine</span><span class="w"> </span><span class="kn">import</span> <span class="n">MaskedTTTEngine</span>
</span></code></pre></div>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="n">engine</span> <span class="o">=</span> <span class="n">MaskedTTTEngine</span><span class="p">(</span>
</span><span id="line-2">    <span class="n">model</span><span class="o">=</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">classifier</span><span class="p">),</span>
</span><span id="line-3">    <span class="n">mask_token_id</span><span class="o">=</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">mask_token_id</span><span class="p">,</span>
</span><span id="line-4">    <span class="n">features_layer_name</span><span class="o">=</span><span class="s2">"mlm_head.predictions"</span><span class="p">,</span>
</span><span id="line-5">    <span class="n">mask_prob</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
</span><span id="line-6">    <span class="n">skip_tokens</span><span class="o">=</span><span class="p">[</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">cls_token_id</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">sep_token_id</span><span class="p">]</span>
</span><span id="line-7"><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</span><span id="line-8">
</span><span id="line-9"><span class="n">engine</span><span class="o">.</span><span class="n">optimization_parameters</span><span class="p">[</span><span class="s2">"num_steps"</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</span><span id="line-10"><span class="n">engine</span><span class="o">.</span><span class="n">optimization_parameters</span><span class="p">[</span><span class="s2">"lr"</span><span class="p">]</span> <span class="o">=</span> <span class="mf">3e-5</span>
</span></code></pre></div>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="n">engine</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</span><span id="line-2"><span class="n">all_preds</span><span class="p">,</span> <span class="n">all_labels</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
</span><span id="line-3"><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tqdm</span><span class="p">(</span><span class="n">corrupted_val_loader</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">corrupted_val_loader</span><span class="p">))):</span>
</span><span id="line-4">    <span class="n">batch</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
</span><span id="line-5">    <span class="n">outputs</span><span class="p">,</span> <span class="n">ttt_loss</span> <span class="o">=</span> <span class="n">engine</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
</span><span id="line-6">    <span class="n">preds</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">logits</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span><span id="line-7">    <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s1">'labels'</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span><span id="line-8">    <span class="n">all_preds</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span>
</span><span id="line-9">    <span class="n">all_labels</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
</span><span id="line-10">
</span><span id="line-11"><span class="n">acc</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">all_labels</span><span class="p">,</span> <span class="n">all_preds</span><span class="p">)</span>
</span><span id="line-12"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Validation Accuracy after epoch: </span><span class="si">{</span><span class="n">acc</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</span></code></pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span><code><span id="line-1">  0%|          | 0/52 [00:00&lt;?, ?it/s]
</span><span id="line-2">  2%|▏         | 1/52 [00:02&lt;01:47,  2.12s/it]
</span><span id="line-3">  4%|▍         | 2/52 [00:02&lt;00:52,  1.06s/it]
</span><span id="line-4">  6%|▌         | 3/52 [00:02&lt;00:35,  1.36it/s]
</span><span id="line-5">  8%|▊         | 4/52 [00:03&lt;00:27,  1.75it/s]
</span><span id="line-6"> 10%|▉         | 5/52 [00:03&lt;00:22,  2.11it/s]
</span><span id="line-7"> 12%|█▏        | 6/52 [00:03&lt;00:19,  2.38it/s]
</span><span id="line-8"> 13%|█▎        | 7/52 [00:04&lt;00:17,  2.62it/s]
</span><span id="line-9"> 15%|█▌        | 8/52 [00:04&lt;00:15,  2.81it/s]
</span><span id="line-10"> 17%|█▋        | 9/52 [00:04&lt;00:14,  2.94it/s]
</span><span id="line-11"> 19%|█▉        | 10/52 [00:04&lt;00:13,  3.04it/s]
</span><span id="line-12"> 21%|██        | 11/52 [00:05&lt;00:15,  2.57it/s]
</span><span id="line-13"> 23%|██▎       | 12/52 [00:05&lt;00:14,  2.76it/s]
</span><span id="line-14"> 25%|██▌       | 13/52 [00:06&lt;00:13,  2.89it/s]
</span><span id="line-15"> 27%|██▋       | 14/52 [00:06&lt;00:12,  3.06it/s]
</span><span id="line-16"> 29%|██▉       | 15/52 [00:06&lt;00:11,  3.18it/s]
</span><span id="line-17"> 31%|███       | 16/52 [00:06&lt;00:11,  3.24it/s]
</span><span id="line-18"> 33%|███▎      | 17/52 [00:07&lt;00:10,  3.31it/s]
</span><span id="line-19"> 35%|███▍      | 18/52 [00:07&lt;00:10,  3.38it/s]
</span><span id="line-20"> 37%|███▋      | 19/52 [00:07&lt;00:09,  3.43it/s]
</span><span id="line-21"> 38%|███▊      | 20/52 [00:08&lt;00:09,  3.45it/s]
</span><span id="line-22"> 40%|████      | 21/52 [00:08&lt;00:09,  3.43it/s]
</span><span id="line-23"> 42%|████▏     | 22/52 [00:08&lt;00:08,  3.42it/s]
</span><span id="line-24"> 44%|████▍     | 23/52 [00:08&lt;00:08,  3.36it/s]
</span><span id="line-25"> 46%|████▌     | 24/52 [00:09&lt;00:08,  3.33it/s]
</span><span id="line-26"> 48%|████▊     | 25/52 [00:09&lt;00:08,  3.31it/s]
</span><span id="line-27"> 50%|█████     | 26/52 [00:09&lt;00:07,  3.30it/s]
</span><span id="line-28"> 52%|█████▏    | 27/52 [00:10&lt;00:07,  3.30it/s]
</span><span id="line-29"> 54%|█████▍    | 28/52 [00:10&lt;00:07,  3.29it/s]
</span><span id="line-30"> 56%|█████▌    | 29/52 [00:10&lt;00:06,  3.29it/s]
</span><span id="line-31"> 58%|█████▊    | 30/52 [00:11&lt;00:06,  3.28it/s]
</span><span id="line-32"> 60%|█████▉    | 31/52 [00:11&lt;00:07,  2.83it/s]
</span><span id="line-33"> 62%|██████▏   | 32/52 [00:11&lt;00:06,  2.95it/s]
</span><span id="line-34"> 63%|██████▎   | 33/52 [00:12&lt;00:06,  3.05it/s]
</span><span id="line-35"> 65%|██████▌   | 34/52 [00:12&lt;00:05,  3.11it/s]
</span><span id="line-36"> 67%|██████▋   | 35/52 [00:12&lt;00:05,  3.15it/s]
</span><span id="line-37"> 69%|██████▉   | 36/52 [00:13&lt;00:05,  3.19it/s]
</span><span id="line-38"> 71%|███████   | 37/52 [00:13&lt;00:04,  3.22it/s]
</span><span id="line-39"> 73%|███████▎  | 38/52 [00:13&lt;00:04,  3.24it/s]
</span><span id="line-40"> 75%|███████▌  | 39/52 [00:14&lt;00:03,  3.26it/s]
</span><span id="line-41"> 77%|███████▋  | 40/52 [00:14&lt;00:03,  3.28it/s]
</span><span id="line-42"> 79%|███████▉  | 41/52 [00:14&lt;00:03,  3.29it/s]
</span><span id="line-43"> 81%|████████  | 42/52 [00:14&lt;00:03,  3.29it/s]
</span><span id="line-44"> 83%|████████▎ | 43/52 [00:15&lt;00:02,  3.30it/s]
</span><span id="line-45"> 85%|████████▍ | 44/52 [00:15&lt;00:02,  3.27it/s]
</span><span id="line-46"> 87%|████████▋ | 45/52 [00:15&lt;00:02,  3.27it/s]
</span><span id="line-47"> 88%|████████▊ | 46/52 [00:16&lt;00:01,  3.31it/s]
</span><span id="line-48"> 90%|█████████ | 47/52 [00:16&lt;00:01,  3.30it/s]
</span><span id="line-49"> 92%|█████████▏| 48/52 [00:16&lt;00:01,  3.31it/s]
</span><span id="line-50"> 94%|█████████▍| 49/52 [00:17&lt;00:00,  3.32it/s]
</span><span id="line-51"> 96%|█████████▌| 50/52 [00:17&lt;00:00,  3.31it/s]
</span><span id="line-52"> 98%|█████████▊| 51/52 [00:17&lt;00:00,  2.84it/s]
</span><span id="line-53">100%|██████████| 52/52 [00:17&lt;00:00,  3.51it/s]
</span><span id="line-54">100%|██████████| 52/52 [00:18&lt;00:00,  2.88it/s]
</span><span id="line-55">Validation Accuracy after epoch: 0.4560
</span></code></pre></div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (7 minutes 29.852 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-03-mae-bert-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/12b373a31cb7f564a68ae5a34744434d/03_mae_bert.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">03_mae_bert.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/3f99fa9ab2f2a1ba17ad1f1363449d70/03_mae_bert.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">03_mae_bert.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../_downloads/99d8229e5030660abd37fdb2f2fb16fb/03_mae_bert.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">03_mae_bert.zip</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>
</div><div class="flex justify-between items-center pt-6 mt-12 border-t border-border gap-4">
<div class="mr-auto">
<a class="inline-flex items-center justify-center rounded-md text-sm font-medium transition-colors border border-input hover:bg-accent hover:text-accent-foreground py-2 px-4" href="02_imagenet_tent.html">
<svg class="mr-2 h-4 w-4" fill="none" height="24" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
<polyline points="15 18 9 12 15 6"></polyline>
</svg>
        ImageNet Robustness with TENT
      </a>
</div>
<div class="ml-auto">
<a class="inline-flex items-center justify-center rounded-md text-sm font-medium transition-colors border border-input hover:bg-accent hover:text-accent-foreground py-2 px-4" href="../papers.html">
        Papers
        <svg class="ml-2 h-4 w-4" fill="none" height="24" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
<polyline points="9 18 15 12 9 6"></polyline>
</svg>
</a>
</div>
</div></div><aside class="hidden text-sm xl:block" id="right-sidebar">
<div class="sticky top-16 -mt-10 max-h-[calc(100vh-5rem)] h-full overflow-y-auto pt-6 space-y-2"><p class="font-medium">On this page</p>
<ul>
<li><a :data-current="activeSection === '#helper-functions'" class="reference internal" href="#helper-functions">Helper Functions</a><ul>
<li><a :data-current="activeSection === '#data-preparation'" class="reference internal" href="#data-preparation">Data Preparation</a></li>
</ul>
</li>
<li><a :data-current="activeSection === '#loading-wilds-dataset'" class="reference internal" href="#loading-wilds-dataset">Loading WILDS dataset</a></li>
<li><a :data-current="activeSection === '#loading-pretrained-bert'" class="reference internal" href="#loading-pretrained-bert">Loading Pretrained BERT</a></li>
<li><a :data-current="activeSection === '#finetuning-bert'" class="reference internal" href="#finetuning-bert">Finetuning BERT</a></li>
<li><a :data-current="activeSection === '#evalating-bert-on-corrupted-data'" class="reference internal" href="#evalating-bert-on-corrupted-data">Evalating BERT on Corrupted Data</a></li>
<li><a :data-current="activeSection === '#masked-test-time-training-for-generalization'" class="reference internal" href="#masked-test-time-training-for-generalization">Masked Test-Time Training for Generalization</a></li>
</ul>
</div>
</aside>
</main>
</div>
</div><footer class="py-6 border-t border-border md:py-0">
<div class="container flex flex-col items-center justify-between gap-4 md:h-24 md:flex-row">
<div class="flex flex-col items-center gap-4 px-8 md:flex-row md:gap-2 md:px-0">
<p class="text-sm leading-loose text-center text-muted-foreground md:text-left">© 2024, Nikita Durasov Built with <a class="font-medium underline underline-offset-4" href="https://www.sphinx-doc.org" rel="noreferrer">Sphinx 8.1.3</a></p>
</div>
</div>
</footer>
</div>
<script src="../_static/documentation_options.js?v=5929fcd5"></script>
<script src="../_static/doctools.js?v=9bcbadda"></script>
<script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
<script defer="defer" src="../_static/theme.js?v=e14a7d8a"></script>
<script src="../_static/js/theme.js?v=f24de042"></script>
</body>
</html>