{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# TTT for Corrupted MNIST\n\nExplore how test-time training can enhance model performance on corrupted MNIST data.\n\nIn this tutorial, we will explore how the original image rotation-based [Test-Time Training (TTT)](http://proceedings.mlr.press/v119/sun20b/sun20b.pdf) approach can improve model performance during inference when the data is corrupted by Gaussian noise, using the [torch-ttt](https://github.com/nikitadurasov/torch-ttt) *Engine* functionality.\n\nThis notebook is designed to demonstrate how seamlessly test-time training approaches can be integrated through [torch-ttt](https://github.com/nikitadurasov/torch-ttt) into existing training and testing pipelines, while also showcasing the significant performance improvements achievable when applying TTT on corrupted or out-of-distribution data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Regular Model (without TTT)\n\nBelow, we will start by training regular networks on MNIST data and demonstrate how susceptible it is to noise introduced during testing, resulting in significantly lower accuracy when the noise is present.\n\n### Data and Model\n\nLet's start with some global parameters that we will use later.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nimport torchvision\nimport numpy as np\nimport random\nimport tqdm\nimport matplotlib.pyplot as plt\n\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nn_epochs = 1  # number of training epochs\nbatch_size_train = 64  # batch size during training\nbatch_size_test = 32  # batch size during training\nlearning_rate = 0.01  # training learning rate\n\nrandom_seed = 7\ntorch.backends.cudnn.enabled = False\ntorch.manual_seed(random_seed)\nrandom.seed(random_seed)\nnp.random.seed(random_seed)\n\n# sphinx_gallery_thumbnail_path = '_static/images/examples/mnist_noisy.png'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will employ a fairly shallow and simple model, consisting only of several convolutional and linear layers with LeakyReLU activations.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50, 50)\n        self.fc3 = nn.Linear(50, 10)\n        self.activation = nn.LeakyReLU()\n\n    def forward(self, x):\n        x = self.activation(F.max_pool2d(self.conv1(x), 2))\n        x = self.activation(F.max_pool2d(self.conv2(x), 2))\n        x = x.view(-1, 320)\n        x = self.activation(self.fc1(x))\n        x = self.activation(self.fc2(x))\n        x = self.fc3(x)\n        return F.log_softmax(x, dim=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For training and testing data, we will use the standard train/test MNIST split, which consists of roughly 60,000 samples for training and 10,000 for testing, and we will normalize the data.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n    torchvision.datasets.MNIST(\n        \"./MNIST/\",\n        train=True,\n        download=True,\n        transform=torchvision.transforms.Compose(\n            [\n                torchvision.transforms.ToTensor(),\n                torchvision.transforms.Normalize((0.1307,), (0.3081,)),\n            ]\n        ),\n    ),\n    batch_size=batch_size_train,\n    shuffle=False,\n)\n\ntest_loader = torch.utils.data.DataLoader(\n    torchvision.datasets.MNIST(\n        \"./MNIST/\",\n        train=False,\n        download=True,\n        transform=torchvision.transforms.Compose(\n            [\n                torchvision.transforms.ToTensor(),\n                torchvision.transforms.Normalize((0.1307,), (0.3081,)),\n            ]\n        ),\n    ),\n    batch_size=batch_size_test,\n    shuffle=False,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, let's visualize 10 random images from the clean MNIST test set. As we can see, the digits are clearly visible and distinctive.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "images, _ = next(iter(test_loader))\nfig, axes = plt.subplots(1, 10, figsize=(15, 2))\nfor ax, img in zip(axes, images[:10, 0]):\n    ax.imshow(img, cmap=\"viridis\")\n    ax.axis(\"off\")\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training and Testing\n\nFollowing a rather simple training pipeline, we train our model for one epoch and then evaluate it on the test set.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "network = Net()\noptimizer = optim.Adam(network.parameters(), lr=learning_rate)\n\n\ndef train():\n    network.train()\n    correct = 0\n    with tqdm.tqdm(total=len(train_loader), desc=\"Train\") as pbar:\n        for batch_idx, (data, target) in enumerate(train_loader):\n            optimizer.zero_grad()\n            output = network(data)\n            pred = output.data.max(1, keepdim=True)[1]\n            correct += pred.eq(target.data.view_as(pred)).sum().item()\n            loss = F.nll_loss(output, target)\n            loss.backward()\n            optimizer.step()\n\n            if (batch_idx + 1) % 150 == 0:\n                pbar.update(150)\n\n        pbar.set_postfix(acc=correct / len(train_loader.dataset))\n\n\ndef test():\n    network.eval()\n    correct = 0\n    with torch.no_grad():\n        with tqdm.tqdm(total=len(test_loader), desc=\"Test\") as pbar:\n            for batch_idx, (data, target) in enumerate(test_loader):\n                output = network(data)\n                pred = output.data.max(1, keepdim=True)[1]\n                correct += pred.eq(target.data.view_as(pred)).sum().item()\n                if (batch_idx + 1) % 100 == 0:\n                    pbar.update(100)\n\n            accuracy = 100.0 * correct / len(test_loader.dataset)\n            pbar.set_postfix(acc=accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we can see below, our model achieves roughly 95% accuracy on both the train and test sets.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for _ in range(n_epochs):\n    train()\ntest()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluating on noisy test\n\nNow, let's add a significant amount of Gaussian noise to our input images, which will make the classification task significantly more challenging. Let's plot how they look.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "images, _ = next(iter(test_loader))\nfig, axes = plt.subplots(1, 10, figsize=(15, 2))\nfor ax, img in zip(axes, images[:10, 0]):\n    noisy_img = img + 2 * torch.randn(img.shape)\n    ax.imshow(noisy_img, cmap=\"viridis\")\n    ax.axis(\"off\")\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since the model was not exposed to this type of corruption during training, these new corrupted inputs can be considered out-of-distribution. As a result, the model shows significantly lower accuracy on these inputs. As we can see below, the accuracy drops from roughly 95% to below 60%.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "network.eval()\ncorrect = 0\nwith torch.no_grad():\n    with tqdm.tqdm(total=len(test_loader), desc=\"Test\") as pbar:\n        for batch_idx, (data, target) in enumerate(test_loader):\n            data += 2 * torch.randn(data.shape)\n            output = network(data)\n            pred = output.data.max(1, keepdim=True)[1]\n            correct += pred.eq(target.data.view_as(pred)).sum().item()\n            if (batch_idx + 1) % 100 == 0:\n                pbar.update(100)\n\n        accuracy = 100.0 * correct / len(test_loader.dataset)\n        pbar.set_postfix(acc=accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optimized Model (with TTT)\n\nNow, let's employ the original [TTT](http://proceedings.mlr.press/v119/sun20b/sun20b.pdf) approach to improve the performance on these noisy inputs. We will use the **TTTEngine** class, which encapsulates the mechanism of TTT's image rotation-based self-supervised loss and gradient optimization during inference.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torch_ttt.engine.ttt_engine import TTTEngine  # noqa: E402"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test-Time Training (TTT) leverages a self-supervised auxiliary task to adapt the model to unseen data distributions during inference. In the training phase, the model is optimized jointly for the primary task and the auxiliary self-supervised task\u2014here, image rotation prediction. This involves learning shared features through the encoder $\\theta_{e}$ while the supervised task head $\\theta_{m}$ (e.g. classification) and self-supervised task head $\\theta_{s}$ (rotation angle prediction) specialize in their respective objectives.\n\nDuring testing, the model adapts to out-of-distribution or noisy inputs by optimizing the self-supervised loss associated with the auxiliary task, enhancing the robustness of primary task predictions. Our **TTTEngine** class seamlessly implements both the training and testing behaviors of the TTT framework, as demonstrated in the example below. For a more detailed overview of the TTT framework, please refer to the original [webpage](https://yueatsprograms.github.io/ttt/home.html) and [slides](https://yueatsprograms.github.io/ttt/slides.pdf).\n\n.. figure:: ../../_static/images/examples/ttt_schema.png\n  :alt: map to buried treasure\n\n  *Figure 1.* **Overview of the TTT framework.** It incorporates joint training with supervised and self-supervised tasks (image rotation prediction) and adapts during inference by optimizing the self-supervised loss for improved predictions.\n\n### Training and Testing\n\nWe need to add only a couple of new lines to our original training and testing functions to introduce TTT into the existing pipelines. Below, we add a comment for each line that was either newly added or modified.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "network = Net()\nengine = TTTEngine(network, \"fc2\")  # create an engine object\noptimizer = optim.Adam(engine.parameters(), lr=learning_rate)  # optimize the engine, not model\n\n\ndef train():\n    engine.train()  # switch engine to .train() mode\n    correct = 0\n    with tqdm.tqdm(total=len(train_loader), desc=\"Train\") as pbar:\n        for batch_idx, (data, target) in enumerate(train_loader):\n            optimizer.zero_grad()\n            output, loss_ttt = engine(data)  # run inferece with engine\n            pred = output.data.max(1, keepdim=True)[1]\n            correct += pred.eq(target.data.view_as(pred)).sum().item()\n            loss = (\n                F.nll_loss(output, target) + 0.35 * loss_ttt\n            )  # add self-supervised loss to the total loss\n            loss.backward()\n            optimizer.step()\n\n            if (batch_idx + 1) % 150 == 0:\n                pbar.update(150)\n\n        pbar.set_postfix(acc=correct / len(train_loader.dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As shown below, the accuracy of the underlying model remains the same for both the original training and the TTT-based training.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for _ in range(n_epochs):\n    train()\ntest()  # evaluation of the underlying model, without TTT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluating on noisy test\n\nNow, let's return to the evaluation of the model on inputs when a significant amount of noise is introduced. As we saw before, the original model demonstrated a significant drop in accuracy when the noise was introduced. Below, we will enable test-time training optimization during inference (which happens in the engine's `.forward()` function) to improve the model's performance on noisy images. As with the training, we will mark the changed/modified lines with a comment.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def ttt_test():\n    engine.eval()  # switch engine to .eval() mode\n    correct = 0\n    with tqdm.tqdm(total=len(test_loader), desc=\"Test\") as pbar:\n        for batch_idx, (data, target) in enumerate(test_loader):\n            data += 2 * torch.randn(data.shape)\n            output, _ = engine(data)  # run inferece with engine\n            pred = output.data.max(1, keepdim=True)[1]\n            correct += pred.eq(target.data.view_as(pred)).sum().item()\n            if (batch_idx + 1) % 100 == 0:\n                pbar.update(100)\n\n        accuracy = 100.0 * correct / len(test_loader.dataset)\n        pbar.set_postfix(acc=accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The engine's *optimization_parameters* dictionary stores the parameters used for optimization. Below, we modify the number of optimization steps to demonstrate how accuracy improves as the number of steps increases. As shown, the TTT engine with 3 optimization iterations improves the accuracy from ~54% for the original model by almost 15%, and further improvements can be achieved with more optimization steps.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"### No optimization ###\")\nengine.optimization_parameters[\"num_steps\"] = 0\nttt_test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"### Number of optimization steps: 1 ###\")\nengine.optimization_parameters[\"num_steps\"] = 1\nttt_test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"### Number of optimization steps: 2 ###\")\nengine.optimization_parameters[\"num_steps\"] = 2\nttt_test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"### Number of optimization steps: 3 ###\")\nengine.optimization_parameters[\"num_steps\"] = 3\nttt_test()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}