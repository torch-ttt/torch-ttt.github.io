<!DOCTYPE html>

<html data-content_root="./" lang="en" x-data="{activeSection: ''}">
<head>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<meta charset="utf-8"/>
<meta content="#ffffff" media="(prefers-color-scheme: light)" name="theme-color"/>
<meta content="#030711" media="(prefers-color-scheme: dark)" name="theme-color"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>

<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-NRNXK42JKJ"></script>
<script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-NRNXK42JKJ');
    </script>
<title>Papers | torch-ttt</title>
<meta content="Papers | torch&lt;span style='border-radius: 4px; color: white; text-justify: none; padding: 0px 2px 0px 2px; background: linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3)); -moz-linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3)); -webkit-linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3));'&gt;-ttt&lt;/span&gt;" property="og:title"/>
<meta content="Papers | torch&lt;span style='border-radius: 4px; color: white; text-justify: none; padding: 0px 2px 0px 2px; background: linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3)); -moz-linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3)); -webkit-linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3));'&gt;-ttt&lt;/span&gt;" name="twitter:title"/>
<link href="_static/pygments.css?v=82fa1eaf" rel="stylesheet" type="text/css"/>
<link href="_static/theme.css?v=c0d22bf5" rel="stylesheet" type="text/css"/>
<link href="_static/sg_gallery.css?v=d2d258e8" rel="stylesheet" type="text/css"/>
<link href="_static/sg_gallery-binder.css?v=f4aeca0c" rel="stylesheet" type="text/css"/>
<link href="_static/sg_gallery-dataframe.css?v=2082cf3c" rel="stylesheet" type="text/css"/>
<link href="_static/sg_gallery-rendered-html.css?v=1277b6f3" rel="stylesheet" type="text/css"/>
<link href="_static/css/custom.css?v=f0970611" rel="stylesheet" type="text/css"/>
<link href="_static/css/docstring_custom.css?v=c7bea3a5" rel="stylesheet" type="text/css"/>
<link href="_static/torch-ttt.svg" rel="icon"/>
<link href="search.html" rel="search" title="Search"/>
<link href="genindex.html" rel="index" title="Index"/>
<link href="api.html" rel="next" title="API Reference"/>
<link href="auto_examples/03_mae_bert.html" rel="prev" title="Test-Time Training for Corrupted WILDS Dataset"/>
</head>
<body :class="{ 'overflow-hidden': showSidebar }" class="min-h-screen font-sans antialiased bg-background text-foreground" x-data="{ showSidebar: false, showScrollTop: false }">
<div @click.self="showSidebar = false" class="fixed inset-0 z-50 overflow-hidden bg-background/80 backdrop-blur-sm md:hidden" x-cloak="" x-show="showSidebar"></div><div class="relative flex flex-col min-h-screen" id="page"><a class="absolute top-0 left-0 z-[100] block bg-background p-4 text-xl transition -translate-x-full opacity-0 focus:translate-x-0 focus:opacity-100" href="#content">
      Skip to content
    </a><header class="sticky top-0 z-40 w-full border-b shadow-sm border-border bg-background/90 backdrop-blur"><div class="container flex items-center h-14">
<div class="hidden mr-4 md:flex">
<a class="flex items-center mr-6" href="index.html">
<img alt="Logo" class="mr-2 dark:invert" height="24" src="_static/torch-ttt.svg" width="24"/><span class="hidden font-bold sm:inline-block text-clip whitespace-nowrap">torch<span style="border-radius: 4px; color: white; text-justify: none; padding: 0px 2px 0px 2px; background: linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3)); -moz-linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3)); -webkit-linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3));">-ttt</span></span>
</a></div><button @click="showSidebar = true" class="inline-flex items-center justify-center h-10 px-0 py-2 mr-2 text-base font-medium transition-colors rounded-md hover:text-accent-foreground hover:bg-transparent md:hidden" type="button">
<svg aria-hidden="true" fill="currentColor" height="24" viewbox="0 96 960 960" width="24" xmlns="http://www.w3.org/2000/svg">
<path d="M152.587 825.087q-19.152 0-32.326-13.174t-13.174-32.326q0-19.152 13.174-32.326t32.326-13.174h440q19.152 0 32.326 13.174t13.174 32.326q0 19.152-13.174 32.326t-32.326 13.174h-440Zm0-203.587q-19.152 0-32.326-13.174T107.087 576q0-19.152 13.174-32.326t32.326-13.174h320q19.152 0 32.326 13.174T518.087 576q0 19.152-13.174 32.326T472.587 621.5h-320Zm0-203.587q-19.152 0-32.326-13.174t-13.174-32.326q0-19.152 13.174-32.326t32.326-13.174h440q19.152 0 32.326 13.174t13.174 32.326q0 19.152-13.174 32.326t-32.326 13.174h-440ZM708.913 576l112.174 112.174q12.674 12.674 12.674 31.826t-12.674 31.826Q808.413 764.5 789.261 764.5t-31.826-12.674l-144-144Q600 594.391 600 576t13.435-31.826l144-144q12.674-12.674 31.826-12.674t31.826 12.674q12.674 12.674 12.674 31.826t-12.674 31.826L708.913 576Z"></path>
</svg>
<span class="sr-only">Toggle navigation menu</span>
</button>
<div class="flex items-center justify-between flex-1 gap-2 sm:gap-4 md:justify-end">
<div class="flex-1 w-full md:w-auto md:flex-none"><form @keydown.k.window.meta="$refs.search.focus()" action="search.html" class="relative flex items-center group" id="searchbox" method="get">
<input aria-label="Search the docs" class="inline-flex items-center font-medium transition-colors bg-transparent focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 ring-offset-background border border-input hover:bg-accent focus:bg-accent hover:text-accent-foreground focus:text-accent-foreground hover:placeholder-accent-foreground py-2 px-4 relative h-9 w-full justify-start rounded-[0.5rem] text-sm text-muted-foreground sm:pr-12 md:w-40 lg:w-64" id="search-input" name="q" placeholder="Search ..." type="search" x-ref="search"/>
<kbd class="pointer-events-none absolute right-1.5 top-2 hidden h-5 select-none text-muted-foreground items-center gap-1 rounded border border-border bg-muted px-1.5 font-mono text-[10px] font-medium opacity-100 sm:flex group-hover:bg-accent group-hover:text-accent-foreground">
<span class="text-xs">âŒ˜</span>
    K
  </kbd>
</form>
</div>
<nav class="flex items-center gap-1">
<a href="https://github.com/nikitadurasov/torch-ttt" rel="noopener nofollow" title="Visit repository on GitHub">
<div class="inline-flex items-center justify-center px-0 text-sm font-medium transition-colors rounded-md hover:bg-accent hover:text-accent-foreground h-9 w-9">
<svg fill="currentColor" height="26px" style="margin-top:-2px;display:inline" viewbox="0 0 45 44" xmlns="http://www.w3.org/2000/svg"><path clip-rule="evenodd" d="M22.477.927C10.485.927.76 10.65.76 22.647c0 9.596 6.223 17.736 14.853 20.608 1.087.2 1.483-.47 1.483-1.047 0-.516-.019-1.881-.03-3.693-6.04 1.312-7.315-2.912-7.315-2.912-.988-2.51-2.412-3.178-2.412-3.178-1.972-1.346.149-1.32.149-1.32 2.18.154 3.327 2.24 3.327 2.24 1.937 3.318 5.084 2.36 6.321 1.803.197-1.403.759-2.36 1.379-2.903-4.823-.548-9.894-2.412-9.894-10.734 0-2.37.847-4.31 2.236-5.828-.224-.55-.969-2.759.214-5.748 0 0 1.822-.584 5.972 2.226 1.732-.482 3.59-.722 5.437-.732 1.845.01 3.703.25 5.437.732 4.147-2.81 5.967-2.226 5.967-2.226 1.185 2.99.44 5.198.217 5.748 1.392 1.517 2.232 3.457 2.232 5.828 0 8.344-5.078 10.18-9.916 10.717.779.67 1.474 1.996 1.474 4.021 0 2.904-.027 5.247-.027 5.96 0 .58.392 1.256 1.493 1.044C37.981 40.375 44.2 32.24 44.2 22.647c0-11.996-9.726-21.72-21.722-21.72" fill="currentColor" fill-rule="evenodd"></path></svg>
</div>
</a>
</nav>
</div>
</div>
</header>
<div class="flex-1"><div class="container md:grid md:grid-cols-[220px_minmax(0,1fr)] md:gap-6 lg:grid-cols-[240px_minmax(0,1fr)] lg:gap-10"><aside :aria-hidden="!showSidebar" :class="{ 'translate-x-0': showSidebar }" class="fixed inset-y-0 left-0 md:top-14 z-50 md:z-30 bg-background md:bg-transparent transition-all duration-100 -translate-x-full md:translate-x-0 ml-0 p-6 md:p-0 md:-ml-2 md:h-[calc(100vh-3.5rem)] w-5/6 md:w-full overflow-y-auto border-r border-border md:sticky" id="left-sidebar">
<a class="justify-start text-sm md:!hidden bg-background" href="index.html">
<img alt="Logo" class="mr-2 dark:invert" height="16" src="_static/torch-ttt.svg" width="16"/><span class="font-bold text-clip whitespace-nowrap">torch<span style="border-radius: 4px; color: white; text-justify: none; padding: 0px 2px 0px 2px; background: linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3)); -moz-linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3)); -webkit-linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3));">-ttt</span></span>
</a>
<div class="relative overflow-hidden md:overflow-auto my-4 md:my-0">
<div class="overflow-y-auto h-full w-full relative pr-6"><nav class="table w-full min-w-full my-6 lg:my-8">
<p class="caption" role="heading"><span class="caption-text">Getting Started:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="quickstart.html">Quick Start</a></li>
<li class="toctree-l1" x-data="{ expanded: $el.classList.contains('current') ? true : false }"><a :class="{ 'expanded' : expanded }" @click="expanded = !expanded" class="reference internal expandable" href="auto_examples/index.html">Tutorials<button @click.prevent.stop="expanded = !expanded" type="button"><span class="sr-only"></span><svg fill="currentColor" height="18px" stroke="none" viewbox="0 0 24 24" width="18px" xmlns="http://www.w3.org/2000/svg"><path d="M10 6L8.59 7.41 13.17 12l-4.58 4.59L10 18l6-6z"></path></svg></button></a><ul x-show="expanded">
<li class="toctree-l2"><a class="reference internal" href="auto_examples/01_mnist_TTT.html">TTT for Corrupted MNIST</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_examples/02_imagenet_tent.html">ImageNet Robustness with TENT</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_examples/03_mae_bert.html">Test-Time Training for Corrupted WILDS Dataset</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Papers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Documentation:</span></p>
<ul>
<li class="toctree-l1" x-data="{ expanded: $el.classList.contains('current') ? true : false }"><a :class="{ 'expanded' : expanded }" @click="expanded = !expanded" class="reference internal expandable" href="api.html">API Reference<button @click.prevent.stop="expanded = !expanded" type="button"><span class="sr-only"></span><svg fill="currentColor" height="18px" stroke="none" viewbox="0 0 24 24" width="18px" xmlns="http://www.w3.org/2000/svg"><path d="M10 6L8.59 7.41 13.17 12l-4.58 4.59L10 18l6-6z"></path></svg></button></a><ul x-show="expanded">
<li class="toctree-l2"><a class="reference internal" href="_autosummary/torch_ttt.engine.ttt_engine.TTTEngine.html">TTTEngine</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/torch_ttt.engine.ttt_pp_engine.TTTPPEngine.html">TTTPPEngine</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/torch_ttt.engine.masked_ttt_engine.MaskedTTTEngine.html">MaskedTTTEngine</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/torch_ttt.engine.actmad_engine.ActMADEngine.html">ActMADEngine</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/torch_ttt.engine.tent_engine.TentEngine.html">TentEngine</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/torch_ttt.engine.eata_engine.EataEngine.html">EataEngine</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/torch_ttt.engine.memo_engine.MemoEngine.html">MemoEngine</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/torch_ttt.engine.deyo_engine.DeYOEngine.html">DeYOEngine</a></li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
<button @click="showSidebar = false" class="absolute md:hidden right-4 top-4 rounded-sm opacity-70 transition-opacity hover:opacity-100" type="button">
<svg class="h-4 w-4" fill="currentColor" height="24" stroke="none" viewbox="0 96 960 960" width="24" xmlns="http://www.w3.org/2000/svg">
<path d="M480 632 284 828q-11 11-28 11t-28-11q-11-11-11-28t11-28l196-196-196-196q-11-11-11-28t11-28q11-11 28-11t28 11l196 196 196-196q11-11 28-11t28 11q11 11 11 28t-11 28L536 576l196 196q11 11 11 28t-11 28q-11 11-28 11t-28-11L480 632Z"></path>
</svg>
</button>
</aside>
<main class="relative py-6 lg:gap-10 lg:py-8 xl:grid xl:grid-cols-[1fr_300px]">
<div class="w-full min-w-0 mx-auto">
<nav aria-label="breadcrumbs" class="flex items-center mb-4 space-x-1 text-sm text-muted-foreground">
<a class="overflow-hidden text-ellipsis whitespace-nowrap hover:text-foreground" href="index.html">
<span class="hidden md:inline">torch<span style="border-radius: 4px; color: white; text-justify: none; padding: 0px 2px 0px 2px; background: linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3)); -moz-linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3)); -webkit-linear-gradient(45deg , rgba(140, 82, 255, 0.3), rgba(255, 145, 77, 0.3));">-ttt</span></span>
<svg aria-label="Home" class="md:hidden" fill="currentColor" height="18" stroke="none" viewbox="0 96 960 960" width="18" xmlns="http://www.w3.org/2000/svg">
<path d="M240 856h120V616h240v240h120V496L480 316 240 496v360Zm-80 80V456l320-240 320 240v480H520V696h-80v240H160Zm320-350Z"></path>
</svg>
</a>
<div class="mr-1">/</div><span aria-current="page" class="font-medium text-foreground overflow-hidden text-ellipsis whitespace-nowrap">Papers</span>
</nav>
<div id="content" role="main">
<section id="papers">
<h1>Papers<a @click.prevent="window.navigator.clipboard.writeText($el.href); $el.setAttribute('data-tooltip', 'Copied!'); setTimeout(() =&gt; $el.setAttribute('data-tooltip', 'Copy link to this element'), 2000)" aria-label="Copy link to this element" class="headerlink" data-tooltip="Copy link to this element" href="#papers"><span>#</span></a></h1>
<p>A curated list of papers on Test-Time Training / Adaptation, inspired by the Awesome list format. This page gathers foundational and recent research focused on enabling models to adapt at test time to improve robustness under distribution shifts.</p>
<script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
<style>
  body {
    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
    margin: 0;
    padding: 20px;
    transition: background-color 0.3s, color 0.3s;
  }
  .controls {
    margin-bottom: 30px;
    text-align: center;
  }
</style>

<div style="width: 100%; max-width: 900px; margin: auto; padding: 0; padding-top: 20px;">
<canvas id="citationsChart"></canvas>
<div style="text-align: justify; font-size: 14px; color: gray; margin-top: 10px;">
<em><b>Figure 1</b>: This plot shows the trend of citations per year for Test-Time Training and Test-Time Adaptation papers listed below. The dashed red line represents the projected citation count for the current year based on the citation trajectory so far. Overall, the visualization illustrates the increasing academic attention and influence of these methods over time.</em>
</div>
</div>
<script>
const ctx = document.getElementById('citationsChart').getContext('2d');
new Chart(ctx, {
    type: 'line',
    data: {
        labels: ['2020', '2021', '2022', '2023', '2024', '2025'],
        datasets: [
          {
            label: 'Citations per Year',
            data: [32, 161, 433, 1288, 2312, 960],
            borderWidth: 2,
            fill: true,
            tension: 0.3,
          },
          {
            label: 'Projected Citations',
            data: [32, 161, 433, 1288, 2312, 3238],
            borderDash: [5,5],
            borderWidth: 2,
            fill: false,
            tension: 0.3,
          }
        ]
    },
    options: {
        responsive: true,
        layout: {
            padding: 0
        },
        plugins: {
            tooltip: {
                mode: 'index',
                intersect: false,
                callbacks: {
                    label: function(context) {
                        return `${context.dataset.label}: ${context.parsed.y}`;
                    }
                }
            },
            legend: {
                display: true
            }
        },
        scales: {
            y: {
                beginAtZero: true,
                ticks: {
                    precision: 0
                }
            }
        },
        hover: {
            mode: 'nearest',
            intersect: true
        }
    }
});
</script>
<style>
  body {
    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
    margin: 0;
    padding: 20px;
    transition: background-color 0.3s, color 0.3s;
  }

  .controls {
    margin-bottom: 30px;
    text-align: center;
  }

  .sort-select {
    padding: 8px 12px;
    font-size: 14px;
    border: 1px solid #ccc;
    border-radius: 5px;
    background-color: #f0f0f0;
    color: #333;
    transition: background-color 0.3s, color 0.3s;
  }

  .papers-container {
    display: grid;
    grid-template-columns: repeat(auto-fill, minmax(280px, 1fr));
    gap: 20px;
  }

  .paper-card {
    border-radius: 12px;
    padding: 20px;
    background-color: #ffffff;
    color: #000000;
    box-shadow: 0 2px 8px rgba(0,0,0,0.1);
    transition: transform 0.2s, box-shadow 0.2s, background-color 0.3s;
    display: flex;
    flex-direction: column;
    height: 100%;
  }

  .paper-card:hover {
    transform: translateY(-5px);
    background-color: #e0f7fa;
    box-shadow: 0 4px 12px rgba(0,0,0,0.2);
    cursor: pointer;
  }

  .paper-top {
    flex: 1;
  }

  .paper-title {
    font-size: 18px;
    font-weight: bold;
    margin-bottom: 10px;
  }

  .paper-authors {
    font-size: 14px;
    margin-bottom: 8px;
  }

  .paper-bottom {
    margin-top: 12px;
    display: flex;
    flex-direction: column;
    justify-content: space-between;
    height: 80px;
  }

  .paper-venue {
    font-size: 14px;
    font-weight: bold;
    color: #9156fe;
  }
  
  .paper-links {
    font-size: 14px;
  }
  
  .paper-citations {
    font-size: 14px;
    color: #ff9e65;
  }

  .paper-trending {
    font-size: 14px;
    color: #e53935;
  }

  .paper-links {
    display: flex;
    gap: 10px;
  }

  .paper-links a {
    color: #4285f4;
  }
  
  .paper-links a:visited {
    color: #4285f4;
  }

  @media (prefers-color-scheme: dark) {
    body {
      background-color: #0d0d0d;
      color: #e0e0e0;
    }
    .sort-select {
      background-color: #1e1e1e;
      color: #e0e0e0;
      border: 1px solid #444;
    }
    .paper-card {
      background-color: #1e1e1e;
      color: #e0e0e0;
      box-shadow: 0 2px 8px rgba(0,0,0,0.6);
    }
    .paper-card:hover {
      background-color: #263238;
      box-shadow: 0 4px 12px rgba(0,0,0,0.8);
      cursor: pointer;
    }
    .paper-citations {
      color: #66bb6a;
    }
    .paper-trending {
      color: #ef5350;
    }
  }
</style>
<div class="controls" style="padding: 10px; padding-top: 50px">
<label for="sortSelect">Sort by:</label>
<select class="sort-select" id="sortSelect" onchange="sortPapers()">
<option value="citations">Citations (high to low)</option>
<option value="trending">Trending ðŸ”¥ (citations last year)</option>
<option value="year">Year (newest first)</option>
<option value="conference">Conference (A-Z)</option>
<option value="title">Title (A-Z)</option>
</select>
</div>
<div class="papers-container" id="papersContainer">
<div class="paper-card" data-authors="Dequan Wang, Evan Shelhamer, Shaoteng Liu, Bruno Olshausen, Trevor Darrell" data-citations="1333" data-conference="ICLR" data-title="TENT: Fully Test-time Adaptation by Entropy Minimization" data-trending="543" data-year="2021">
<div class="paper-top">
<div class="paper-title">TENT: Fully Test-time Adaptation by Entropy Minimization</div>
<div class="paper-authors">Dequan Wang, Evan Shelhamer, Shaoteng Liu, Bruno Olshausen, Trevor Darrell</div>
</div>
<div class="paper-bottom">
<div class="paper-venue">ICLR (2021)</div>
<div class="paper-links"><a href="https://openreview.net/pdf?id=uXl3bZLkr3c" target="_blank">paper</a> | <a href="https://github.com/DequanWang/tent" target="_blank">code</a></div>
<div class="paper-citations">Citations: 1333  <span style="color: red;"><b>(ðŸ”¥ Top Trending)</b></span></div>
</div>
</div>
<div class="paper-card" data-authors="Yu Sun, Xiaolong Wang, Zhuang Liu, John Miller, Alexei A. Efros, Moritz Hardt" data-citations="991" data-conference="ICML" data-title="Test-Time Training with Self-Supervision for Generalization under Distribution Shifts" data-trending="334" data-year="2020">
<div class="paper-top">
<div class="paper-title">Test-Time Training with Self-Supervision for Generalization under Distribution Shifts</div>
<div class="paper-authors">Yu Sun, Xiaolong Wang, Zhuang Liu, John Miller, Alexei A. Efros, Moritz Hardt</div>
</div>
<div class="paper-bottom">
<div class="paper-venue">ICML (2020)</div>
<div class="paper-links"><a href="https://proceedings.mlr.press/v119/sun20b/sun20b.pdf" target="_blank">paper</a> | <a href="https://github.com/yueatsprograms/ttt_cifar_release" target="_blank">code</a></div>
<div class="paper-citations">Citations: 991  <span style="color: red;"><b>(ðŸ”¥ Top Trending)</b></span></div>
</div>
</div>
<div class="paper-card" data-authors="Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Yaofo Chen, Shijian Zheng, Peilin Zhao, Mingkui Tan" data-citations="381" data-conference="ICLR" data-title="Efficient Test-Time Model Adaptation without Forgetting" data-trending="205" data-year="2023">
<div class="paper-top">
<div class="paper-title">Efficient Test-Time Model Adaptation without Forgetting</div>
<div class="paper-authors">Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Yaofo Chen, Shijian Zheng, Peilin Zhao, Mingkui Tan</div>
</div>
<div class="paper-bottom">
<div class="paper-venue">ICLR (2023)</div>
<div class="paper-links"><a href="https://proceedings.mlr.press/v162/niu22a/niu22a.pdf" target="_blank">paper</a> | <a href="https://github.com/mr-eggplant/EATA" target="_blank">code</a></div>
<div class="paper-citations">Citations: 381  <span style="color: red;"><b>(ðŸ”¥ Top Trending)</b></span></div>
</div>
</div>
<div class="paper-card" data-authors="Marvin Zhang, Sergey Levine, Chelsea Finn" data-citations="362" data-conference="NeurIPS" data-title="MEMO: Test Time Robustness via Adaptation and Augmentation" data-trending="174" data-year="2022">
<div class="paper-top">
<div class="paper-title">MEMO: Test Time Robustness via Adaptation and Augmentation</div>
<div class="paper-authors">Marvin Zhang, Sergey Levine, Chelsea Finn</div>
</div>
<div class="paper-bottom">
<div class="paper-venue">NeurIPS (2022)</div>
<div class="paper-links"><a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/fc28053a08f59fccb48b11f2e31e81c7-Paper-Conference.pdf" target="_blank">paper</a> | <a href="https://github.com/zhangmarvin/memo" target="_blank">code</a></div>
<div class="paper-citations">Citations: 362  <span style="color: red;"><b>(ðŸ”¥ Top Trending)</b></span></div>
</div>
</div>
<div class="paper-card" data-authors="Yuejiang Liu, Parth Kothari, Bastien van Delft, Baptiste Bellot-Gurlet, Taylor Mordan, Alexandre Alahi" data-citations="331" data-conference="NeurIPS" data-title="TTT++: When Does Self-Supervised Test-Time Training Fail or Thrive?" data-trending="148" data-year="2021">
<div class="paper-top">
<div class="paper-title">TTT++: When Does Self-Supervised Test-Time Training Fail or Thrive?</div>
<div class="paper-authors">Yuejiang Liu, Parth Kothari, Bastien van Delft, Baptiste Bellot-Gurlet, Taylor Mordan, Alexandre Alahi</div>
</div>
<div class="paper-bottom">
<div class="paper-venue">NeurIPS (2021)</div>
<div class="paper-links"><a href="https://proceedings.neurips.cc/paper_files/paper/2021/file/b618c3210e934362ac261db280128c22-Paper.pdf" target="_blank">paper</a> | <a href="https://github.com/vita-epfl/ttt-plus-plus" target="_blank">code</a></div>
<div class="paper-citations">Citations: 331  <span style="color: red;"><b>(ðŸ”¥ Top Trending)</b></span></div>
</div>
</div>
<div class="paper-card" data-authors="Yusuke Iwasawa, Yutaka Matsuo" data-citations="319" data-conference="NeurIPS" data-title="Test-Time Classifier Adjustment Module for Model-Agnostic Domain Generalization" data-trending="131" data-year="2021">
<div class="paper-top">
<div class="paper-title">Test-Time Classifier Adjustment Module for Model-Agnostic Domain Generalization</div>
<div class="paper-authors">Yusuke Iwasawa, Yutaka Matsuo</div>
</div>
<div class="paper-bottom">
<div class="paper-venue">NeurIPS (2021)</div>
<div class="paper-links"><a href="https://proceedings.neurips.cc/paper_files/paper/2021/file/1415fe9fea0fa1e45dddcff5682239a0-Paper.pdf" target="_blank">paper</a> | <a href="https://github.com/matsuolab/T3A" target="_blank">code</a></div>
<div class="paper-citations">Citations: 319 </div>
</div>
</div>
<div class="paper-card" data-authors="Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Zhiquan Wen, Yaofo Chen, Peilin Zhao, Mingkui Tan" data-citations="305" data-conference="ICLR" data-title="Towards Stable Test-Time Adaptation in Dynamic Wild World" data-trending="181" data-year="2023">
<div class="paper-top">
<div class="paper-title">Towards Stable Test-Time Adaptation in Dynamic Wild World</div>
<div class="paper-authors">Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Zhiquan Wen, Yaofo Chen, Peilin Zhao, Mingkui Tan</div>
</div>
<div class="paper-bottom">
<div class="paper-venue">ICLR (2023)</div>
<div class="paper-links"><a href="https://openreview.net/pdf?id=g2YraF75Tj" target="_blank">paper</a> | <a href="https://github.com/mr-eggplant/SAR" target="_blank">code</a></div>
<div class="paper-citations">Citations: 305  <span style="color: red;"><b>(ðŸ”¥ Top Trending)</b></span></div>
</div>
</div>
<div class="paper-card" data-authors="Jian Liang, Ran He, Tieniu Tan" data-citations="249" data-conference="IJCV" data-title="A Comprehensive Survey on Test-Time Adaptation under Distribution Shifts" data-trending="127" data-year="2024">
<div class="paper-top">
<div class="paper-title">A Comprehensive Survey on Test-Time Adaptation under Distribution Shifts</div>
<div class="paper-authors">Jian Liang, Ran He, Tieniu Tan</div>
</div>
<div class="paper-bottom">
<div class="paper-venue">IJCV (2024)</div>
<div class="paper-links"><a href="https://link.springer.com/article/10.1007/s11263-024-02181-w" target="_blank">paper</a></div>
<div class="paper-citations">Citations: 249 </div>
</div>
</div>
<div class="paper-card" data-authors="Yossi Gandelsman, Yu Sun, Xinlei Chen, Alexei A. Efros" data-citations="191" data-conference="NeurIPS" data-title="Test-Time Training with Masked Autoencoders" data-trending="101" data-year="2022">
<div class="paper-top">
<div class="paper-title">Test-Time Training with Masked Autoencoders</div>
<div class="paper-authors">Yossi Gandelsman, Yu Sun, Xinlei Chen, Alexei A. Efros</div>
</div>
<div class="paper-bottom">
<div class="paper-venue">NeurIPS (2022)</div>
<div class="paper-links"><a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/bcdec1c2d60f94a93b6e36f937aa0530-Paper-Conference.pdf" target="_blank">paper</a> | <a href="https://github.com/yossigandelsman/test_time_training_mae" target="_blank">code</a></div>
<div class="paper-citations">Citations: 191 </div>
</div>
</div>
<div class="paper-card" data-authors="Malik Boudiaf, Romain Mueller, Ismail Ben Ayed, Luca Bertinetto" data-citations="187" data-conference="CVPR" data-title="Parameter-free Online Test-time Adaptation" data-trending="93" data-year="2022">
<div class="paper-top">
<div class="paper-title">Parameter-free Online Test-time Adaptation</div>
<div class="paper-authors">Malik Boudiaf, Romain Mueller, Ismail Ben Ayed, Luca Bertinetto</div>
</div>
<div class="paper-bottom">
<div class="paper-venue">CVPR (2022)</div>
<div class="paper-links"><a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Boudiaf_Parameter-Free_Online_Test-Time_Adaptation_CVPR_2022_paper.pdf" target="_blank">paper</a> | <a href="https://github.com/fiveai/LAME" target="_blank">code</a></div>
<div class="paper-citations">Citations: 187 </div>
</div>
</div>
<div class="paper-card" data-authors="Yu Sun, Xinhao Li, Karan Dalal, Jiarui Xu, Arjun Vikram, Genghan Zhang, Yann Dubois, Xinlei Chen, Xiaolong Wang, Sanmi Koyejo, Tatsunori Hashimoto, Carlos Guestrin" data-citations="90" data-conference="ICLR" data-title="Learning to (Learn at Test Time): RNNs with Expressive Hidden States" data-trending="45" data-year="2025">
<div class="paper-top">
<div class="paper-title">Learning to (Learn at Test Time): RNNs with Expressive Hidden States</div>
<div class="paper-authors">Yu Sun, Xinhao Li, Karan Dalal, Jiarui Xu, Arjun Vikram, Genghan Zhang, Yann Dubois, Xinlei Chen, Xiaolong Wang, Sanmi Koyejo, Tatsunori Hashimoto, Carlos Guestrin</div>
</div>
<div class="paper-bottom">
<div class="paper-venue">ICLR (2025)</div>
<div class="paper-links"><a href="https://openreview.net/pdf?id=eifW0W0xgt" target="_blank">paper</a> | <a href="https://github.com/test-time-training/ttt-lm-pytorch" target="_blank">code</a></div>
<div class="paper-citations">Citations: 90 </div>
</div>
</div>
<div class="paper-card" data-authors="Alexander Bartler, Andre BÃ¼hler, Felix Wiewel, Mario DÃ¶bler, Bin Yang" data-citations="85" data-conference="AISTATS" data-title="MT3: Meta Test-Time Training for Self-Supervised Test-Time Adaption" data-trending="31" data-year="2022">
<div class="paper-top">
<div class="paper-title">MT3: Meta Test-Time Training for Self-Supervised Test-Time Adaption</div>
<div class="paper-authors">Alexander Bartler, Andre BÃ¼hler, Felix Wiewel, Mario DÃ¶bler, Bin Yang</div>
</div>
<div class="paper-bottom">
<div class="paper-venue">AISTATS (2022)</div>
<div class="paper-links"><a href="https://proceedings.mlr.press/v151/bartler22a/bartler22a.pdf" target="_blank">paper</a> | <a href="https://github.com/AlexanderBartler/MT3" target="_blank">code</a></div>
<div class="paper-citations">Citations: 85 </div>
</div>
</div>
<div class="paper-card" data-authors="Bowen Zhao, Chen Chen, Shu-Tao Xia" data-citations="75" data-conference="ICLR" data-title="DELTA: Degradation-Free Fully Test-Time Adaptation" data-trending="45" data-year="2023">
<div class="paper-top">
<div class="paper-title">DELTA: Degradation-Free Fully Test-Time Adaptation</div>
<div class="paper-authors">Bowen Zhao, Chen Chen, Shu-Tao Xia</div>
</div>
<div class="paper-bottom">
<div class="paper-venue">ICLR (2023)</div>
<div class="paper-links"><a href="https://openreview.net/pdf?id=eGm22rqG93" target="_blank">paper</a></div>
<div class="paper-citations">Citations: 75 </div>
</div>
</div>
<div class="paper-card" data-authors="Junyuan Hong, Lingjuan Lyu, Jiayu Zhou, Michael Spranger" data-citations="41" data-conference="ICLR" data-title="MECTA: Memory-Economic Continual Test-Time Model Adaptation" data-trending="23" data-year="2023">
<div class="paper-top">
<div class="paper-title">MECTA: Memory-Economic Continual Test-Time Model Adaptation</div>
<div class="paper-authors">Junyuan Hong, Lingjuan Lyu, Jiayu Zhou, Michael Spranger</div>
</div>
<div class="paper-bottom">
<div class="paper-venue">ICLR (2023)</div>
<div class="paper-links"><a href="https://openreview.net/pdf?id=N92hjSf5NNh" target="_blank">paper</a> | <a href="https://github.com/SonyAI/MECTA" target="_blank">code</a></div>
<div class="paper-citations">Citations: 41 </div>
</div>
</div>
<div class="paper-card" data-authors="Jonghyun Lee, Dahuin Jung, Saehyung Lee, Junsung Park, Juhyeon Shin, Uiwon Hwang, Sungroh Yoon" data-citations="37" data-conference="ICLR" data-title="Entropy is not Enough for Test-Time Adaptation: From the Perspective of Disentangled Factors" data-trending="22" data-year="2024">
<div class="paper-top">
<div class="paper-title">Entropy is not Enough for Test-Time Adaptation: From the Perspective of Disentangled Factors</div>
<div class="paper-authors">Jonghyun Lee, Dahuin Jung, Saehyung Lee, Junsung Park, Juhyeon Shin, Uiwon Hwang, Sungroh Yoon</div>
</div>
<div class="paper-bottom">
<div class="paper-venue">ICLR (2024)</div>
<div class="paper-links"><a href="https://openreview.net/pdf?id=9w3iw8wDuE" target="_blank">paper</a> | <a href="https://github.com/Jhyun17/DeYO" target="_blank">code</a></div>
<div class="paper-citations">Citations: 37 </div>
</div>
</div>
<div class="paper-card" data-authors="David Osowiechi, Gustavo A. Vargas Hakim, Mehrdad Noori, Milad Cheraghalikhani, Ismail Ben Ayed, Christian Desrosiers" data-citations="32" data-conference="WACV" data-title="TTTFlow: Unsupervised Test-Time Training With Normalizing Flow" data-trending="16" data-year="2023">
<div class="paper-top">
<div class="paper-title">TTTFlow: Unsupervised Test-Time Training With Normalizing Flow</div>
<div class="paper-authors">David Osowiechi, Gustavo A. Vargas Hakim, Mehrdad Noori, Milad Cheraghalikhani, Ismail Ben Ayed, Christian Desrosiers</div>
</div>
<div class="paper-bottom">
<div class="paper-venue">WACV (2023)</div>
<div class="paper-links"><a href="https://openaccess.thecvf.com/content/WACV2023/papers/Osowiechi_TTTFlow_Unsupervised_Test-Time_Training_With_Normalizing_Flow_WACV_2023_paper.pdf" target="_blank">paper</a> | <a href="https://github.com/GustavoVargasHakim/TTTFlow" target="_blank">code</a></div>
<div class="paper-citations">Citations: 32 </div>
</div>
</div>
<div class="paper-card" data-authors="Muhammad Jehanzeb Mirza, Pol JanÃ© Soneira, Wei Lin, Mateusz Kozinski, Horst Possegger, Horst Bischof" data-citations="30" data-conference="CVPR" data-title="ActMAD: Activation Matching to Align Distributions for Test-Time-Training" data-trending="18" data-year="2023">
<div class="paper-top">
<div class="paper-title">ActMAD: Activation Matching to Align Distributions for Test-Time-Training</div>
<div class="paper-authors">Muhammad Jehanzeb Mirza, Pol JanÃ© Soneira, Wei Lin, Mateusz Kozinski, Horst Possegger, Horst Bischof</div>
</div>
<div class="paper-bottom">
<div class="paper-venue">CVPR (2023)</div>
<div class="paper-links"><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Mirza_ActMAD_Activation_Matching_To_Align_Distributions_for_Test-Time-Training_CVPR_2023_paper.pdf" target="_blank">paper</a> | <a href="https://github.com/jmiemirza/ActMAD" target="_blank">code</a></div>
<div class="paper-citations">Citations: 30 </div>
</div>
</div>
<div class="paper-card" data-authors="Weihuang Liu, Xi Shen, Haolun Li, Xiuli Bi, Bo Liu, Chi-Man Pun, Xiaodong Cun" data-citations="24" data-conference="CVPR" data-title="Depth-aware Test-Time Training for Zero-shot Video Object Segmentation" data-trending="13" data-year="2024">
<div class="paper-top">
<div class="paper-title">Depth-aware Test-Time Training for Zero-shot Video Object Segmentation</div>
<div class="paper-authors">Weihuang Liu, Xi Shen, Haolun Li, Xiuli Bi, Bo Liu, Chi-Man Pun, Xiaodong Cun</div>
</div>
<div class="paper-bottom">
<div class="paper-venue">CVPR (2024)</div>
<div class="paper-links"><a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Liu_Depth-aware_Test-Time_Training_for_Zero-shot_Video_Object_Segmentation_CVPR_2024_paper.pdf" target="_blank">paper</a> | <a href="https://github.com/NiFangBaAGe/DATTT" target="_blank">code</a></div>
<div class="paper-citations">Citations: 24 </div>
</div>
</div>
<div class="paper-card" data-authors="Moritz Hardt, Yu Sun" data-citations="21" data-conference="ICLR" data-title="Test-Time Training on Nearest Neighbors for Large Language Models" data-trending="11" data-year="2024">
<div class="paper-top">
<div class="paper-title">Test-Time Training on Nearest Neighbors for Large Language Models</div>
<div class="paper-authors">Moritz Hardt, Yu Sun</div>
</div>
<div class="paper-bottom">
<div class="paper-venue">ICLR (2024)</div>
<div class="paper-links"><a href="https://openreview.net/pdf?id=CNL2bku4ra" target="_blank">paper</a> | <a href="https://github.com/socialfoundations/tttlm" target="_blank">code</a></div>
<div class="paper-citations">Citations: 21 </div>
</div>
</div>
<div class="paper-card" data-authors="Ekin AkyÃ¼rek, Mehul Damani, Adam Zweiger, Linlu Qiu, Han Guo, Jyothish Pari, Yoon Kim, Jacob Andreas" data-citations="18" data-conference="arXiv" data-title="The Surprising Effectiveness of Test-Time Training for Few-Shot Learning" data-trending="6" data-year="2024">
<div class="paper-top">
<div class="paper-title">The Surprising Effectiveness of Test-Time Training for Few-Shot Learning</div>
<div class="paper-authors">Ekin AkyÃ¼rek, Mehul Damani, Adam Zweiger, Linlu Qiu, Han Guo, Jyothish Pari, Yoon Kim, Jacob Andreas</div>
</div>
<div class="paper-bottom">
<div class="paper-venue">arXiv (2024)</div>
<div class="paper-links"><a href="https://arxiv.org/pdf/2411.07279" target="_blank">paper</a> | <a href="https://github.com/ekinakyurek/marc" target="_blank">code</a></div>
<div class="paper-citations">Citations: 18 </div>
</div>
</div>
<div class="paper-card" data-authors="Gustavo A. Vargas Hakim, David Osowiechi, Mehrdad Noori, Milad Cheraghalikhani, Ismail Ben Ayed, Christian Desrosiers" data-citations="16" data-conference="ICCV" data-title="ClusT3: Information Invariant Test-Time Training" data-trending="10" data-year="2023">
<div class="paper-top">
<div class="paper-title">ClusT3: Information Invariant Test-Time Training</div>
<div class="paper-authors">Gustavo A. Vargas Hakim, David Osowiechi, Mehrdad Noori, Milad Cheraghalikhani, Ismail Ben Ayed, Christian Desrosiers</div>
</div>
<div class="paper-bottom">
<div class="paper-venue">ICCV (2023)</div>
<div class="paper-links"><a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Hakim_ClusT3_Information_Invariant_Test-Time_Training_ICCV_2023_paper.pdf" target="_blank">paper</a> | <a href="https://github.com/dosowiechi/ClusT3" target="_blank">code</a></div>
<div class="paper-citations">Citations: 16 </div>
</div>
</div>
<div class="paper-card" data-authors="Renhao Wang, Yu Sun, Arnuv Tandon, Yossi Gandelsman, Xinlei Chen, Alexei A. Efros, Xiaolong Wang" data-citations="15" data-conference="JMLR" data-title="Test-Time Training on Video Streams" data-trending="8" data-year="2023">
<div class="paper-top">
<div class="paper-title">Test-Time Training on Video Streams</div>
<div class="paper-authors">Renhao Wang, Yu Sun, Arnuv Tandon, Yossi Gandelsman, Xinlei Chen, Alexei A. Efros, Xiaolong Wang</div>
</div>
<div class="paper-bottom">
<div class="paper-venue">JMLR (2023)</div>
<div class="paper-links"><a href="https://www.jmlr.org/papers/volume26/24-0439/24-0439.pdf" target="_blank">paper</a> | <a href="https://github.com/yossigandelsman/test_time_training_mae" target="_blank">code</a></div>
<div class="paper-citations">Citations: 15 </div>
</div>
</div>
<div class="paper-card" data-authors="Motasem Alfarra, Hani Itani, Alejandro Pardo, Shyma Alhuwaider, Merey Ramazanova, Juan C. PÃ©rez, Zhipeng Cai, Matthias MÃ¼ller, Bernard Ghanem" data-citations="15" data-conference="ICML" data-title="Evaluation of Test-Time Adaptation Under Computational Time Constraints" data-trending="7" data-year="2024">
<div class="paper-top">
<div class="paper-title">Evaluation of Test-Time Adaptation Under Computational Time Constraints</div>
<div class="paper-authors">Motasem Alfarra, Hani Itani, Alejandro Pardo, Shyma Alhuwaider, Merey Ramazanova, Juan C. PÃ©rez, Zhipeng Cai, Matthias MÃ¼ller, Bernard Ghanem</div>
</div>
<div class="paper-bottom">
<div class="paper-venue">ICML (2024)</div>
<div class="paper-links"><a href="https://openreview.net/pdf?id=6FtAXU4ean" target="_blank">paper</a> | <a href="https://github.com/MotasemAlfarra/Online_Test_Time_Adaptation" target="_blank">code</a></div>
<div class="paper-citations">Citations: 15 </div>
</div>
</div>
<div class="paper-card" data-authors="David Osowiechi, Gustavo A. Vargas Hakim, Mehrdad Noori, Milad Cheraghalikhani, Ali Bahri, Moslem Yazdanpanah, Ismail Ben Ayed, Christian Desrosiers" data-citations="13" data-conference="CVPR" data-title="NC-TTT: A Noise Constrastive Approach for Test-Time Training" data-trending="8" data-year="2024">
<div class="paper-top">
<div class="paper-title">NC-TTT: A Noise Constrastive Approach for Test-Time Training</div>
<div class="paper-authors">David Osowiechi, Gustavo A. Vargas Hakim, Mehrdad Noori, Milad Cheraghalikhani, Ali Bahri, Moslem Yazdanpanah, Ismail Ben Ayed, Christian Desrosiers</div>
</div>
<div class="paper-bottom">
<div class="paper-venue">CVPR (2024)</div>
<div class="paper-links"><a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Osowiechi_NC-TTT_A_Noise_Constrastive_Approach_for_Test-Time_Training_CVPR_2024_paper.pdf" target="_blank">paper</a> | <a href="https://github.com/GustavoVargasHakim/NCTTT" target="_blank">code</a></div>
<div class="paper-citations">Citations: 13 </div>
</div>
</div>
<div class="paper-card" data-authors="Yige Yuan, Bingbing Xu, Liang Hou, Fei Sun, Huawei Shen, Xueqi Cheng" data-citations="12" data-conference="CVPR" data-title="TEA: Test-time Energy Adaptation" data-trending="6" data-year="2024">
<div class="paper-top">
<div class="paper-title">TEA: Test-time Energy Adaptation</div>
<div class="paper-authors">Yige Yuan, Bingbing Xu, Liang Hou, Fei Sun, Huawei Shen, Xueqi Cheng</div>
</div>
<div class="paper-bottom">
<div class="paper-venue">CVPR (2024)</div>
<div class="paper-links"><a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Yuan_TEA_Test-time_Energy_Adaptation_CVPR_2024_paper.pdf" target="_blank">paper</a> | <a href="https://github.com/yuanyige/tea" target="_blank">code</a></div>
<div class="paper-citations">Citations: 12 </div>
</div>
</div>
<div class="paper-card" data-authors="Hongbin Lin, Yifan Zhang, Shuaicheng Niu, Shuguang Cui, Zhen Li" data-citations="7" data-conference="ECCV" data-title="MonoTTA: Fully Test-Time Adaptation for Monocular 3D Object Detection" data-trending="4" data-year="2024">
<div class="paper-top">
<div class="paper-title">MonoTTA: Fully Test-Time Adaptation for Monocular 3D Object Detection</div>
<div class="paper-authors">Hongbin Lin, Yifan Zhang, Shuaicheng Niu, Shuguang Cui, Zhen Li</div>
</div>
<div class="paper-bottom">
<div class="paper-venue">ECCV (2024)</div>
<div class="paper-links"><a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/06035.pdf" target="_blank">paper</a> | <a href="https://github.com/Hongbin98/MonoTTA" target="_blank">code</a></div>
<div class="paper-citations">Citations: 7 </div>
</div>
</div>
<div class="paper-card" data-authors="Jonas HÃ¼botter, Sascha Bongni, Ido Hakimi, Andreas Krause" data-citations="6" data-conference="ICLR" data-title="Efficiently Learning at Test-Time: Active Fine-Tuning of LLMs" data-trending="2" data-year="2025">
<div class="paper-top">
<div class="paper-title">Efficiently Learning at Test-Time: Active Fine-Tuning of LLMs</div>
<div class="paper-authors">Jonas HÃ¼botter, Sascha Bongni, Ido Hakimi, Andreas Krause</div>
</div>
<div class="paper-bottom">
<div class="paper-venue">ICLR (2025)</div>
<div class="paper-links"><a href="https://openreview.net/pdf?id=NS1G1Uhny3" target="_blank">paper</a> | <a href="https://github.com/jonhue/activeft" target="_blank">code</a></div>
<div class="paper-citations">Citations: 6 </div>
</div>
</div>
</div>
<script>
function sortPapers() {
  const container = document.getElementById('papersContainer');
  const cards = Array.from(container.getElementsByClassName('paper-card'));
  const sortValue = document.getElementById('sortSelect').value;

  cards.sort((a, b) => {
    if (sortValue === 'citations') {
      return parseInt(b.dataset.citations) - parseInt(a.dataset.citations);
    } else if (sortValue === 'trending') {
      return parseInt(b.dataset.trending) - parseInt(a.dataset.trending);
    } else if (sortValue === 'year') {
      return parseInt(b.dataset.year) - parseInt(a.dataset.year);
    } else if (sortValue === 'conference') {
      return a.dataset.conference.localeCompare(b.dataset.conference);
    } else if (sortValue === 'title') {
      return a.dataset.title.localeCompare(b.dataset.title);
    }
  });

  container.innerHTML = '';
  cards.forEach(card => container.appendChild(card));
}
</script>
</section>
</div><div class="flex justify-between items-center pt-6 mt-12 border-t border-border gap-4">
<div class="mr-auto">
<a class="inline-flex items-center justify-center rounded-md text-sm font-medium transition-colors border border-input hover:bg-accent hover:text-accent-foreground py-2 px-4" href="auto_examples/03_mae_bert.html">
<svg class="mr-2 h-4 w-4" fill="none" height="24" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
<polyline points="15 18 9 12 15 6"></polyline>
</svg>
        Test-Time Training for Corrupted WILDS Dataset
      </a>
</div>
<div class="ml-auto">
<a class="inline-flex items-center justify-center rounded-md text-sm font-medium transition-colors border border-input hover:bg-accent hover:text-accent-foreground py-2 px-4" href="api.html">
        API Reference
        <svg class="ml-2 h-4 w-4" fill="none" height="24" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
<polyline points="9 18 15 12 9 6"></polyline>
</svg>
</a>
</div>
</div></div>
</main>
</div>
</div><footer class="py-6 border-t border-border md:py-0">
<div class="container flex flex-col items-center justify-between gap-4 md:h-24 md:flex-row">
<div class="flex flex-col items-center gap-4 px-8 md:flex-row md:gap-2 md:px-0">
<p class="text-sm leading-loose text-center text-muted-foreground md:text-left">Â© 2024, Nikita DurasovÂ Built with <a class="font-medium underline underline-offset-4" href="https://www.sphinx-doc.org" rel="noreferrer">Sphinx 8.1.3</a></p>
</div>
</div>
</footer>
</div>
<script src="_static/documentation_options.js?v=5929fcd5"></script>
<script src="_static/doctools.js?v=9bcbadda"></script>
<script src="_static/sphinx_highlight.js?v=dc90522c"></script>
<script defer="defer" src="_static/theme.js?v=e14a7d8a"></script>
<script src="_static/js/theme.js?v=f24de042"></script>
</body>
</html>