{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Test-Time Training with BERT\n\nDiscover how Masked Test-Time Training can improve model performance under data corruption.\n\nIn this tutorial, we use a pretrained BERT model fine-tuned on the Amazon Reviews dataset. During inference, we show how simple text corruptions can significantly degrade the model's performance and how the [MaskedTTT](https://torch-ttt.github.io/_autosummary/torch_ttt.engine.masked_ttt_engine.MaskedTTTEngine.html) engine can natively enhance performance for BERT-based models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Uncomment the line below to install torch-ttt if you're running this in Colab\")\n# !pip install torch-ttt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Fine-Tuning\nIn this first part, we will use a widely adopted pretrained BERT model and fine-tune it on a Amazon Reviews classification task. Below, we walk through data loading and preparation, loading the pretrained BERT model, and its fine-tuning.\n\n### Data Preparation\nWe will work with the Amazon Reviews dataset, which contains customer reviews for a wide range of products.\nTo simulate distribution shift, we will use both a clean version of the dataset and a corrupted version that includes noise in the form of typos and text perturbations.\nFor this tutorial, we'll focus on a single corruption type: character-level typos.\n\nLet's start by downloading the training and validation splits of our Amazon Reviews dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\n\n# Download Amazon Review \"electronics\" category training set\nos.system(\"gdown 1mpswNa37wFhcGd-U07nMUFeF0_X4AEMi\")\n\n# Download Amazon Review \"electronics\" category validation set\nos.system(\"gdown 1UbhmtFn7GEMmcoKdb2lbpf54yZV9mLoF\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom sklearn.metrics import accuracy_score\nfrom transformers.modeling_outputs import SequenceClassifierOutput\nfrom tqdm import tqdm\nfrom copy import deepcopy\n\n# sphinx_gallery_thumbnail_path = '_static/images/examples/bert_horizonal.png'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loading Amazon Reviews\nEach review consists of the review text and a score (from 0 to 4), ranging from most negative to most positive. As we will see below, we treat this as a text classification task, where each review is classified into one of these five classes.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nfrom torch.utils.data import DataLoader\nfrom transformers import BertTokenizer, BertForSequenceClassification\nfrom transformers import get_scheduler\nfrom sklearn.metrics import accuracy_score\nfrom tqdm import tqdm\nfrom torch.utils.data import Subset\n\n# Set device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nclass AmazonReviewDataset(Dataset):\n    def __init__(self, path):\n        super().__init__()\n        # Load the list of (text, label, input_ids)\n        self.data = torch.load(path)  # or use json.load(...) if it's a JSON file\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        text, label, input_ids = self.data[idx]\n        label = torch.tensor(label)\n        input_ids = torch.tensor(input_ids)\n        return text, label, input_ids\n\ntrain_data = AmazonReviewDataset(\"train_amazon_review_electronics.pt\")\nval_data = AmazonReviewDataset(\"test_amazon_review_electronics.pt\")\n\n# Review Examples\nreview_sample = train_data[0]\nprint(\"*\"*20 + \" Review #1 \" + \"*\"*20)\nprint(f\"Review text: {review_sample[0]}\")\nprint(f\"Review score: {review_sample[1]} (from 0 to 4)\\n\")\n\nreview_sample = train_data[10]\nprint(\"*\"*20 + \" Review #2 \" + \"*\"*20)\nprint(f\"Review text: {review_sample[0]}\")\nprint(f\"Review score: {review_sample[1]}\\n\")\n\nreview_sample = train_data[100]\nprint(\"*\"*20 + \" Review #3 \" + \"*\"*20)\nprint(f\"Review text: {review_sample[0]}\")\nprint(f\"Review score: {review_sample[1]}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loading Pretrained BERT\nIn this subsection, we load a pretrained BERT model with a Masked Language Modeling (MLM) head. \nWe demonstrate how BERT predicts missing words by masking a token in a sentence and retrieving \nthe top predictions using the MLM head. This showcases the model's ability to understand context \nand semantics in text, which we will later leverage in our Test-Time Training approach.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nfrom transformers import BertTokenizer, BertModel, BertConfig\nfrom transformers.models.bert.modeling_bert import BertLMPredictionHead, BertForMaskedLM\n\n# Load tokenizer, config, and base BERT (no head)\ntokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\") #bert-base-uncased\nconfig = BertConfig.from_pretrained(\"bert-base-uncased\")\n\n# Load a full BERT with pretrained MLM head\nmlm_model = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")\n\n# Extract encoder and MLM head from it\nbert = mlm_model.bert\nmlm_head = mlm_model.cls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the example below, we mask one of the words in a sentence and use the MLM head to predict \nthe missing token. The model returns the most likely candidates to fill in the blank, illustrating \nits contextual understanding of language.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "text = \"The Milky Way is a spiral [MASK].\"\ninputs = tokenizer(text, return_tensors=\"pt\")\ninput_ids = inputs[\"input_ids\"]\n\n# Get index of [MASK] token\nmask_token_index = torch.where(input_ids == tokenizer.mask_token_id)[1]\n\n# Forward pass through BERT to get hidden states\nwith torch.no_grad():\n    outputs = bert(**inputs, return_dict=True)\n    hidden_states = outputs.last_hidden_state  # (batch_size, seq_len, hidden_dim)\n\n# Apply MLM head to get logits over vocabulary\nlogits = mlm_head(hidden_states)  # (batch_size, seq_len, vocab_size)\n\n# Get logits at [MASK] position\nmask_logits = logits[0, mask_token_index, :]  # shape: (1, vocab_size)\n\n# Get top-3 predicted tokens\ntop_3_tokens = torch.topk(mask_logits, k=5, dim=1).indices[0].tolist()\n\n# Print predictions\nprint(\"\\n\\n\" + \"*\"*20 + \" BERT-based Token Reconstruction \" + \"*\"*20)\nprint(\"Original:\", text)\nfor i, token_id in enumerate(top_3_tokens):\n    predicted_token = tokenizer.decode([token_id])\n    filled_text = text.replace(tokenizer.mask_token, predicted_token)\n    print(f\"{i+1}. {filled_text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fine-tuning BERT\nWe now fine-tune the pretrained BERT encoder for a multi-class sentiment classification task using the Amazon Reviews dataset. To address class imbalance, we compute class frequencies and apply a *WeightedRandomSampler* to ensure balanced training.\n\nWe define a custom classification head on top of BERT, consisting of several fully connected layers, and use the [CLS] token representation for prediction. The model is trained using cross-entropy loss with class weights, and a learning rate scheduler is set up for stable optimization.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nimport random\nimport numpy as np\n\nseed = 42\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\nnp.random.seed(seed)\nrandom.seed(seed)\n\ndevice = \"cuda\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n\n# Class frequencies (heavily imbalanced)\nlabels = [train_data[i][1].item() for i in range(len(train_data))]\nsorted_freq = sorted(Counter([int(x) for x in labels]).items(), key=lambda x: x[0])\nfor f in sorted_freq:\n  print(f\"Class {f[0]}: {f[1]} samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import WeightedRandomSampler\n\n# Compute weights per class\nclass_counts = np.bincount(labels)\nclass_weights = 1. / class_counts\nsample_weights = class_weights[labels]\n\n# Create weighted sampler for Dataloader\nsampler = WeightedRandomSampler(\n    weights=sample_weights,\n    num_samples=len(sample_weights),\n    replacement=True\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Class sample counts\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "counts = torch.tensor([x[1] for x in sorted_freq], dtype=torch.float)\n\n# Inverse frequency\ninv_freq = 1.0 / counts\n\n# Normalize (optional but recommended)\nweights = inv_freq / inv_freq.sum()\n\n# Classification head (on top of BERT)\nclass BertForClassification(nn.Module):\n    def __init__(self, bert, mlm_head, num_classes=2):\n        super().__init__()\n        self.bert = bert  # the encoder you already have\n        self.dropout = nn.Dropout(0.0)\n        self.mlm_head = mlm_head\n        self.classifier = nn.Sequential(\n            nn.Linear(bert.config.hidden_size, 128),\n            nn.ELU(),\n            nn.Linear(128, 64),\n            nn.ELU(),\n            nn.Linear(64, num_classes)\n        )\n\n    def forward(self, input_ids, attention_mask, **kwargs):\n        labels = kwargs.get(\"labels\", None)\n\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n\n        # Take [CLS] token\n        cls_token = outputs.last_hidden_state[:, 0, :]\n        x = self.dropout(cls_token)\n        logits = self.classifier(x)\n\n        mlm_embeddings = self.mlm_head(outputs.last_hidden_state)\n\n        # Optional loss\n        loss = None\n        if labels is not None:\n            loss = nn.CrossEntropyLoss(weight=weights.to(logits.device))(logits, labels)\n\n        return SequenceClassifierOutput(\n            loss=loss,\n            logits=logits,\n            hidden_states=outputs.hidden_states,\n            attentions=outputs.attentions,\n        )\n\n# Initialize classifier model\nclassifier = BertForClassification(bert, mlm_head, num_classes=5).to(device)\nclassifier = classifier.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Training parameters**: We use the standard BERT tokenizer from HuggingFace. All training parameters\u2014such as the number of epochs, batch size, and learning rate\u2014are listed below.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n\ndef tokenize_batch(batch):\n    return tokenizer(batch['text'], padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n\n# Custom collate function for DataLoader\ndef collate_fn(batch):\n    # print(batch[0])\n    texts = [x[0] for x in batch]\n    labels = torch.tensor([x[1] for x in batch])\n    tokenized = tokenizer(texts, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n    return {**tokenized, 'labels': labels}\n\nnum_workers = 32\nepochs_num = 20\ntrain_loader = DataLoader(train_data, batch_size=num_workers, num_workers=num_workers, collate_fn=collate_fn, sampler=sampler)\nval_loader = DataLoader(val_data, batch_size=num_workers, num_workers=num_workers, shuffle=False, collate_fn=collate_fn)\n\n# Optimizer\nclassifier.to(device)\noptimizer = torch.optim.AdamW(classifier.parameters(), lr=1e-4)\nlr_scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=100,\n                             num_training_steps=len(train_loader)*epochs_num)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Training loop**: Here we fine-tune the BERT classifier using weighted cross-entropy and the AdamW optimizer with a learning rate scheduler. After each epoch, we evaluate accuracy on the validation set to track performance.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for epoch in range(epochs_num):\n    classifier.train()\n    for i, batch in enumerate(train_loader):\n        batch = {k: v.to(device) for k, v in batch.items()}\n        outputs = classifier(**batch)\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()\n        lr_scheduler.step()\n        optimizer.zero_grad()\n\n    # Validation\n    classifier.eval()\n    all_preds, all_labels = [], []\n    with torch.no_grad():\n        for i, batch in enumerate(val_loader):\n            batch = {k: v.to(device) for k, v in batch.items()}\n            outputs = classifier(**batch)\n            preds = outputs.logits.argmax(dim=-1).cpu().numpy()\n            labels = batch['labels'].cpu().numpy()\n            all_preds.extend(preds)\n            all_labels.extend(labels)\n\n    acc = accuracy_score(all_labels, all_preds)\n    print(f\"Validation Accuracy after epoch {epoch+1}: {acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Validation Evaluation**: After fine-tuning, our BERT model achieves approximately 60% accuracy on the Amazon Reviews test set.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "classifier = classifier.eval()\nall_preds, all_labels = [], []\nwith torch.no_grad():\n    for i, batch in enumerate(val_loader):\n        batch = {k: v.to(device) for k, v in batch.items()}\n        outputs = classifier(**batch)\n        preds = outputs.logits.argmax(dim=-1).cpu().numpy()\n        labels = batch['labels'].cpu().numpy()\n        all_preds.extend(preds)\n        all_labels.extend(labels)\n\nacc = accuracy_score(all_labels, all_preds)\nprint(f\"Validation Accuracy (FINAL): {acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Original BERT Evaluation\nIn this section, we simulate real-world noise by applying text corruptions\u2014such as character swaps, deletions, and word shuffling\u2014to the validation set. We define a *CorruptedDataset* wrapper that dynamically applies these perturbations during data loading.\n\nWe then evaluate the fine-tuned BERT classifier from the previous sections on this corrupted data to measure its robustness. As expected, even minor textual noise can lead to a noticeable drop in performance, highlighting the need for techniques like Test-Time Training.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluating BERT on Corrupted Data\nWe start by defining simple text corruption functions that simulate real-world noise, such as typos and word scrambling.\nThese include character-level operations (e.g., dropping, swapping, or repeating characters) and word-level perturbations \n(e.g., deleting or shuffling words). We combine these operations to create corrupted versions of clean input text,\nwhich will later be used to assess how well the fine-tuned BERT model performs on noisy inputs.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import random\n\ndef corrupt_characters(text, prob=0.1):\n    \"\"\"Randomly drop, swap, and repeat characters.\"\"\"\n    corrupted = []\n    for word in text.split():\n        chars = list(word)\n        for i in range(len(chars)):\n            if random.random() < prob:\n                op = random.choice(['swap', 'drop', 'repeat'])\n                if op == 'swap' and i < len(chars) - 1:\n                    chars[i], chars[i+1] = chars[i+1], chars[i]\n                elif op == 'drop':\n                    chars[i] = ''\n                elif op == 'repeat':\n                    chars[i] = chars[i] * 2\n        corrupted.append(''.join(chars))\n    return ' '.join(corrupted)\n\ndef corrupt_words(text, prob=0.2):\n    \"\"\"Randomly drop and shuffle words.\"\"\"\n    words = text.split()\n    new_words = []\n\n    for word in words:\n        if random.random() < prob:\n            op = random.choice(['delete', 'shuffle'])\n            if op == 'delete':\n                continue\n            elif op == 'shuffle' and len(word) > 3:\n                middle = list(word[1:-1])\n                random.shuffle(middle)\n                word = word[0] + ''.join(middle) + word[-1]\n        new_words.append(word)\n    return ' '.join(new_words)\n\ndef corrupt_text(text, char_prob=0.1, word_prob=0.2):\n    return corrupt_characters(corrupt_words(text, word_prob), char_prob)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Text corruption example**: Below we show how a clean sentence is transformed by our corruption functions,\nsimulating real-world noise such as typos, deletions, and character swaps.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "text = \"This is an example of a clean sentence\"\n\nprint(f\"Original text: {text}\")\n\ncorrupted_text = corrupt_text(text, 0.1, 0.1)\nprint(f\"Corrupted text: {corrupted_text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets define a dataset wrapper that applies text corruptions on-the-fly during data loading. \nThis allows us to evaluate the model's robustness without modifying the original dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class CorruptedDataset(Dataset):\n\n    def __init__(self, dataset, char_prob=0.1, word_prob=0.1):\n        self.dataset = dataset\n        self.char_prob = char_prob\n        self.word_prob = word_prob\n\n    def __getitem__(self, idx):\n        sample = self.dataset[idx]\n        text = sample[0]\n        corrupted_text = corrupt_text(text, self.char_prob, self.word_prob)\n        return (corrupted_text, sample[1], sample[2])\n\n    def __len__(self):\n        return len(self.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "corrupted_val_data = CorruptedDataset(val_data, char_prob=0.1, word_prob=0.1)\ncorrupted_val_loader = DataLoader(corrupted_val_data, batch_size=num_workers, num_workers=num_workers, shuffle=True, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Model Evaluation on Corrupted Data**: We now evaluate our fine-tuned BERT model on the corrupted validation set. As shown below, the presence of perturbations significantly degrades classification performance, with a drop of around 20%.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "all_preds, all_labels = [], []\nwith torch.no_grad():\n    for i, batch in enumerate(corrupted_val_loader):\n        batch = {k: v.to(device) for k, v in batch.items()}\n        outputs = classifier(**batch)\n        preds = outputs.logits.argmax(dim=-1).cpu().numpy()\n        labels = batch['labels'].cpu().numpy()\n        all_preds.extend(preds)\n        all_labels.extend(labels)\n\nacc = accuracy_score(all_labels, all_preds)\nprint(f\"Validation Accuracy after epoch: {acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## TTT-Optimized BERT Evaluation\nWe evaluate the BERT model enhanced with Masked Test-Time Training (MaskedTTT) on the corrupted validation set.\nThe TTT engine performs an adaptation step during inference, using masked tokens and self-supervised\nMLM loss to refine the model\u2019s final prediction. As shown below, this approach recovers some performance lost\ndue to input corruptions and improves accuracy compared to the non-adapted model.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluating Optimized BERT on Corrupted Data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torch_ttt.engine.masked_ttt_engine import MaskedTTTEngine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "engine = MaskedTTTEngine(\n    model=deepcopy(classifier),\n    mask_token_id=tokenizer.mask_token_id,\n    features_layer_name=\"mlm_head.predictions\",\n    mask_prob=0.1,\n    skip_tokens=[tokenizer.pad_token_id, tokenizer.cls_token_id, tokenizer.sep_token_id]\n).eval()\n\nengine.optimization_parameters[\"num_steps\"] = 1\nengine.optimization_parameters[\"lr\"] = 3e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "engine.eval()\nall_preds, all_labels = [], []\nfor i, batch in enumerate(tqdm(corrupted_val_loader, total=len(corrupted_val_loader))):\n    batch = {k: v.to(device) for k, v in batch.items()}\n    outputs, ttt_loss = engine(batch)\n    preds = outputs.logits.argmax(dim=-1).cpu().numpy()\n    labels = batch['labels'].cpu().numpy()\n    all_preds.extend(preds)\n    all_labels.extend(labels)\n\nacc = accuracy_score(all_labels, all_preds)\nprint(f\"Validation Accuracy after epoch: {acc:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}