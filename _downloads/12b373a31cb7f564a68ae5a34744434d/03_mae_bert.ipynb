{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Test-Time Training for Corrupted WILDS Dataset\n\nExplore how Test-Time Training (TTT) can improve model performance under data corruption,\nusing the BERT model fine-tuned with a MaskedTTT engine on the Amazon Reviews dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Uncomment the line below to install torch-ttt if you're running this in Colab\")\n# !pip install git+https://github.com/nikitadurasov/torch-ttt.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper Functions\n\n### Data Preparation\nWe will work with the Amazon Reviews dataset, which contains customer reviews for a wide range of products.\nTo simulate distribution shift, we will use both a clean version of the dataset and a corrupted version that includes noise in the form of typos and text perturbations.\nFor this tutorial, we'll focus on a single corruption type: character-level typos.\n\nLet's start by downloading both the clean and corrupted versions of the Amazon Reviews dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\n\n# Download Amazon Review \"electronics\" category training set\nos.system(\"gdown 1mpswNa37wFhcGd-U07nMUFeF0_X4AEMi\")\n\n# Download Amazon Review \"electronics\" category validation set\nos.system(\"gdown 1UbhmtFn7GEMmcoKdb2lbpf54yZV9mLoF\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom sklearn.metrics import accuracy_score\nfrom transformers.modeling_outputs import SequenceClassifierOutput\nfrom tqdm import tqdm\nfrom copy import deepcopy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading WILDS dataset\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nfrom torch.utils.data import DataLoader\nfrom transformers import BertTokenizer, BertForSequenceClassification\nfrom transformers import get_scheduler\nfrom sklearn.metrics import accuracy_score\nfrom tqdm import tqdm\nfrom torch.utils.data import Subset\n\n# Set device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nclass AmazonReviewDataset(Dataset):\n    def __init__(self, path):\n        super().__init__()\n        # Load the list of (text, label, input_ids)\n        self.data = torch.load(path)  # or use json.load(...) if it's a JSON file\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        text, label, input_ids = self.data[idx]\n        label = torch.tensor(label)\n        input_ids = torch.tensor(input_ids)\n        return text, label, input_ids\n\ntrain_data = AmazonReviewDataset(\"train_amazon_review_electronics.pt\")\nval_data = AmazonReviewDataset(\"test_amazon_review_electronics.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading Pretrained BERT\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nfrom transformers import BertTokenizer, BertModel, BertConfig\nfrom transformers.models.bert.modeling_bert import BertLMPredictionHead, BertForMaskedLM\n\n# Load tokenizer, config, and base BERT (no head)\ntokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\") #bert-base-uncased\nconfig = BertConfig.from_pretrained(\"bert-base-uncased\")\n\n# Load a full BERT with pretrained MLM head\nmlm_model = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")\n\n# Extract encoder and MLM head from it\nbert = mlm_model.bert\nmlm_head = mlm_model.cls\n\n# Input sentence with a masked token\ntext = \"The Milky Way is a spiral [MASK].\"\ninputs = tokenizer(text, return_tensors=\"pt\")\ninput_ids = inputs[\"input_ids\"]\n\n# Get index of [MASK] token\nmask_token_index = torch.where(input_ids == tokenizer.mask_token_id)[1]\n\n# Forward pass through BERT to get hidden states\nwith torch.no_grad():\n    outputs = bert(**inputs, return_dict=True)\n    hidden_states = outputs.last_hidden_state  # (batch_size, seq_len, hidden_dim)\n\n# Apply MLM head to get logits over vocabulary\nlogits = mlm_head(hidden_states)  # (batch_size, seq_len, vocab_size)\n\n# Get logits at [MASK] position\nmask_logits = logits[0, mask_token_index, :]  # shape: (1, vocab_size)\n\n# Get top-3 predicted tokens\ntop_3_tokens = torch.topk(mask_logits, k=5, dim=1).indices[0].tolist()\n\n# Print predictions\nprint(\"Original:\", text)\nfor i, token_id in enumerate(top_3_tokens):\n    predicted_token = tokenizer.decode([token_id])\n    filled_text = text.replace(tokenizer.mask_token, predicted_token)\n    print(f\"{i+1}. {filled_text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Finetuning BERT\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nimport random\nimport numpy as np\n\nseed = 42\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\nnp.random.seed(seed)\nrandom.seed(seed)\n\ndevice = \"cuda\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from collections import Counter\nlabels = [train_data[i][1].item() for i in range(len(train_data))]\nsorted_freq = sorted(Counter([int(x) for x in labels]).items(), key=lambda x: x[0])\nprint(sorted_freq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import WeightedRandomSampler\n\n# Count samples per class\nclass_counts = np.bincount(labels)\nclass_weights = 1. / class_counts\nsample_weights = class_weights[labels]\n\nsampler = WeightedRandomSampler(\n    weights=sample_weights,\n    num_samples=len(sample_weights),\n    replacement=True\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Class sample counts\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "counts = torch.tensor([x[1] for x in sorted_freq], dtype=torch.float)\n\n# Inverse frequency\ninv_freq = 1.0 / counts\n\n# Normalize (optional but recommended)\nweights = inv_freq / inv_freq.sum()\n\n# Classification head (on top of BERT)\nclass BertForClassification(nn.Module):\n    def __init__(self, bert, mlm_head, num_classes=2):\n        super().__init__()\n        self.bert = bert  # the encoder you already have\n        self.dropout = nn.Dropout(0.0)\n        self.mlm_head = mlm_head\n        self.classifier = nn.Sequential(\n            nn.Linear(bert.config.hidden_size, 128),\n            nn.ELU(),\n            nn.Linear(128, 64),\n            nn.ELU(),\n            nn.Linear(64, num_classes)\n        )\n\n    def forward(self, input_ids, attention_mask, **kwargs):\n        labels = kwargs.get(\"labels\", None)\n\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n\n        # Take [CLS] token\n        cls_token = outputs.last_hidden_state[:, 0, :]\n        x = self.dropout(cls_token)\n        logits = self.classifier(x)\n\n        mlm_embeddings = self.mlm_head(outputs.last_hidden_state)\n\n        # Optional loss\n        loss = None\n        if labels is not None:\n            loss = nn.CrossEntropyLoss(weight=weights.to(logits.device))(logits, labels)\n\n        return SequenceClassifierOutput(\n            loss=loss,\n            logits=logits,\n            hidden_states=outputs.hidden_states,\n            attentions=outputs.attentions,\n        )\n\n# Initialize classifier model\nclassifier = BertForClassification(bert, mlm_head, num_classes=5).to(device)\nclassifier = classifier.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use HuggingFace tokenizer\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n\ndef tokenize_batch(batch):\n    return tokenizer(batch['text'], padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n\n# Custom collate function for DataLoader\ndef collate_fn(batch):\n    # print(batch[0])\n    texts = [x[0] for x in batch]\n    labels = torch.tensor([x[1] for x in batch])\n    tokenized = tokenizer(texts, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n    return {**tokenized, 'labels': labels}\n\nnum_workers = 32\nepochs_num = 20\ntrain_loader = DataLoader(train_data, batch_size=num_workers, num_workers=num_workers, collate_fn=collate_fn, sampler=sampler)\nval_loader = DataLoader(val_data, batch_size=num_workers, num_workers=num_workers, shuffle=False, collate_fn=collate_fn)\n\n# Optimizer\nclassifier.to(device)\noptimizer = torch.optim.AdamW(classifier.parameters(), lr=1e-4)\nlr_scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=100,\n                             num_training_steps=len(train_loader)*epochs_num)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Training loop\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for epoch in range(epochs_num):\n    classifier.train()\n    for i, batch in enumerate(train_loader):\n        batch = {k: v.to(device) for k, v in batch.items()}\n        outputs = classifier(**batch)\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()\n        lr_scheduler.step()\n        optimizer.zero_grad()\n\n    # Validation\n    classifier.eval()\n    all_preds, all_labels = [], []\n    with torch.no_grad():\n        for i, batch in enumerate(val_loader):\n            batch = {k: v.to(device) for k, v in batch.items()}\n            outputs = classifier(**batch)\n            preds = outputs.logits.argmax(dim=-1).cpu().numpy()\n            labels = batch['labels'].cpu().numpy()\n            all_preds.extend(preds)\n            all_labels.extend(labels)\n\n    acc = accuracy_score(all_labels, all_preds)\n    print(f\"Validation Accuracy after epoch {epoch+1}: {acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Validation\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "classifier = classifier.eval()\nall_preds, all_labels = [], []\nwith torch.no_grad():\n    for i, batch in enumerate(tqdm(val_loader, total=len(val_loader))):\n        batch = {k: v.to(device) for k, v in batch.items()}\n        outputs = classifier(**batch)\n        preds = outputs.logits.argmax(dim=-1).cpu().numpy()\n        labels = batch['labels'].cpu().numpy()\n        all_preds.extend(preds)\n        all_labels.extend(labels)\n\nacc = accuracy_score(all_labels, all_preds)\nprint(f\"Validation Accuracy after epoch: {acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evalating BERT on Corrupted Data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import random\n\ndef corrupt_characters(text, prob=0.1):\n    corrupted = []\n    for word in text.split():\n        chars = list(word)\n        for i in range(len(chars)):\n            if random.random() < prob:\n                op = random.choice(['swap', 'drop', 'repeat'])\n                if op == 'swap' and i < len(chars) - 1:\n                    chars[i], chars[i+1] = chars[i+1], chars[i]\n                elif op == 'drop':\n                    chars[i] = ''\n                elif op == 'repeat':\n                    chars[i] = chars[i] * 2\n        corrupted.append(''.join(chars))\n    return ' '.join(corrupted)\n\ndef corrupt_words(text, prob=0.2):\n    words = text.split()\n    new_words = []\n\n    for word in words:\n        if random.random() < prob:\n            op = random.choice(['delete', 'shuffle'])\n            if op == 'delete':\n                continue\n            elif op == 'shuffle' and len(word) > 3:\n                middle = list(word[1:-1])\n                random.shuffle(middle)\n                word = word[0] + ''.join(middle) + word[-1]\n        new_words.append(word)\n    return ' '.join(new_words)\n\ndef corrupt_text(text, char_prob=0.1, word_prob=0.2):\n    return corrupt_characters(corrupt_words(text, word_prob), char_prob)\n\nclass CorruptedDataset(Dataset):\n\n    def __init__(self, dataset, char_prob=0.1, word_prob=0.1):\n        self.dataset = dataset\n        self.char_prob = char_prob\n        self.word_prob = word_prob\n\n    def __getitem__(self, idx):\n        sample = self.dataset[idx]\n        text = sample[0]\n        corrupted_text = corrupt_text(text, self.char_prob, self.word_prob)\n        return (corrupted_text, sample[1], sample[2])\n\n    def __len__(self):\n        return len(self.dataset)\n\ntext = \"This is an example of a corrupted sentence using Python\"\nprint(corrupt_text(text, 0.1, 0.1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "corrupted_val_data = CorruptedDataset(val_data, char_prob=0.1, word_prob=0.1)\ncorrupted_val_loader = DataLoader(corrupted_val_data, batch_size=num_workers, num_workers=num_workers, shuffle=True, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Corrupted Validation\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "classifier = classifier.eval()\nall_preds, all_labels = [], []\nwith torch.no_grad():\n    for i, batch in enumerate(tqdm(corrupted_val_loader, total=len(corrupted_val_loader))):\n        batch = {k: v.to(device) for k, v in batch.items()}\n        outputs = classifier(**batch)\n        preds = outputs.logits.argmax(dim=-1).cpu().numpy()\n        labels = batch['labels'].cpu().numpy()\n        all_preds.extend(preds)\n        all_labels.extend(labels)\n\nacc = accuracy_score(all_labels, all_preds)\nprint(f\"Validation Accuracy after epoch: {acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Masked Test-Time Training for Generalization\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torch_ttt.engine.masked_ttt_engine import MaskedTTTEngine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "engine = MaskedTTTEngine(\n    model=deepcopy(classifier),\n    mask_token_id=tokenizer.mask_token_id,\n    features_layer_name=\"mlm_head.predictions\",\n    mask_prob=0.1,\n    skip_tokens=[tokenizer.pad_token_id, tokenizer.cls_token_id, tokenizer.sep_token_id]\n).eval()\n\nengine.optimization_parameters[\"num_steps\"] = 1\nengine.optimization_parameters[\"lr\"] = 3e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "engine.eval()\nall_preds, all_labels = [], []\nfor i, batch in enumerate(tqdm(corrupted_val_loader, total=len(corrupted_val_loader))):\n    batch = {k: v.to(device) for k, v in batch.items()}\n    outputs, ttt_loss = engine(batch)\n    preds = outputs.logits.argmax(dim=-1).cpu().numpy()\n    labels = batch['labels'].cpu().numpy()\n    all_preds.extend(preds)\n    all_labels.extend(labels)\n\nacc = accuracy_score(all_labels, all_preds)\nprint(f\"Validation Accuracy after epoch: {acc:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}